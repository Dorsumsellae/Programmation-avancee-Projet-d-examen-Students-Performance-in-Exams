{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse exploratoire complète des données (EDA)\n",
    "\n",
    "**Auteur:** Louis Vanacker\n",
    "\n",
    "**Date:** 7 janvier 2026\n",
    "\n",
    "**Objectif:** Réaliser une analyse exploratoire complète du jeu de données Students Performance in Exams.\n",
    "\n",
    "## Table des matières\n",
    "1. [Chargement et aperçu des données](#1)\n",
    "2. [Analyse univariée](#2)\n",
    "3. [Analyse bivariée](#3)\n",
    "4. [Analyse multivariée](#4)\n",
    "5. [Feature Engineering](#5)\n",
    "6. [Conclusions et insights](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1. Chargement et aperçu des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration du style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print('Bibliothèques importées avec succès')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "url = \"https://raw.githubusercontent.com/Dorsumsellae/Programmation-avancee-Projet-d-examen-Students-Performance-in-Exams/main/data/raw/StudentsPerformance.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(f'Dataset chargé : {df.shape[0]} lignes, {df.shape[1]} colonnes')\n",
    "print('\\nAperçu des 5 premières lignes :')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informations sur le dataset\n",
    "print('=== INFORMATIONS SUR LE DATASET ===')\n",
    "df.info()\n",
    "\n",
    "print('\\n=== STATISTIQUES DESCRIPTIVES ===')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la qualité des données\n",
    "print('=== QUALITÉ DES DONNÉES ===')\n",
    "print(f'\\nValeurs manquantes : {df.isnull().sum().sum()}')\n",
    "print(f'Doublons : {df.duplicated().sum()}')\n",
    "print('\\nTypes de données :')\n",
    "print(df.dtypes)\n",
    "print('\\nValeurs uniques par colonne :')\n",
    "for col in df.columns:\n",
    "    print(f'  - {col}: {df[col].nunique()} valeurs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2. Analyse univariée\n",
    "\n",
    "### 2.1 Variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des variables\n",
    "categorical_cols = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
    "score_cols = ['math score', 'reading score', 'writing score']\n",
    "\n",
    "print('=== ANALYSE DES VARIABLES CATÉGORIELLES ===')\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f'\\n{col.upper()}:')\n",
    "    print(df[col].value_counts())\n",
    "    print(f'\\nDistribution en % :')\n",
    "    print(df[col].value_counts(normalize=True).mul(100).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des variables catégorielles\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    counts = df[col].value_counts()\n",
    "    axes[i].bar(range(len(counts)), counts.values, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    axes[i].set_xticks(range(len(counts)))\n",
    "    axes[i].set_xticklabels(counts.index, rotation=45, ha='right')\n",
    "    axes[i].set_title(f'Distribution de {col}', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_ylabel('Effectif', fontsize=11)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for j, v in enumerate(counts.values):\n",
    "        axes[i].text(j, v + 10, f'{v}\\n({v/len(df)*100:.1f}%)', \n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "fig.delaxes(axes[5])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Variables numériques (Scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== STATISTIQUES DES SCORES ===')\n",
    "print(df[score_cols].describe())\n",
    "\n",
    "print('\\n=== STATISTIQUES DÉTAILLÉES PAR SCORE ===')\n",
    "\n",
    "for col in score_cols:\n",
    "    print(f'\\n{col.upper()}:')\n",
    "    print(f'  Moyenne     : {df[col].mean():.2f}')\n",
    "    print(f'  Médiane     : {df[col].median():.2f}')\n",
    "    print(f'  Mode        : {df[col].mode()[0]}')\n",
    "    print(f'  Écart-type  : {df[col].std():.2f}')\n",
    "    print(f'  Variance    : {df[col].var():.2f}')\n",
    "    print(f'  Skewness    : {df[col].skew():.2f}')\n",
    "    print(f'  Kurtosis    : {df[col].kurtosis():.2f}')\n",
    "    print(f'  Min         : {df[col].min()}')\n",
    "    print(f'  Max         : {df[col].max()}')\n",
    "    print(f'  Étendue     : {df[col].max() - df[col].min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions des scores avec statistiques\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, col in enumerate(score_cols):\n",
    "    axes[i].hist(df[col], bins=20, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "    axes[i].axvline(df[col].mean(), color='red', linestyle='--', linewidth=2,\n",
    "                   label=f'Moyenne: {df[col].mean():.1f}')\n",
    "    axes[i].axvline(df[col].median(), color='green', linestyle='--', linewidth=2,\n",
    "                   label=f'Médiane: {df[col].median():.1f}')\n",
    "    axes[i].set_title(f'Distribution de {col}', fontsize=14, fontweight='bold')\n",
    "    axes[i].set_xlabel('Score', fontsize=12)\n",
    "    axes[i].set_ylabel('Fréquence', fontsize=12)\n",
    "    axes[i].legend(fontsize=10)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots pour détecter les outliers\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, col in enumerate(score_cols):\n",
    "    bp = axes[i].boxplot(df[col], vert=True, patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('lightblue')\n",
    "    bp['boxes'][0].set_edgecolor('black')\n",
    "    axes[i].set_title(f'{col} - Boîte à moustaches', fontsize=14, fontweight='bold')\n",
    "    axes[i].set_ylabel('Score', fontsize=12)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détection des valeurs aberrantes (méthode IQR)\n",
    "print('=== DÉTECTION DES VALEURS ABERRANTES (MÉTHODE IQR) ===')\n",
    "\n",
    "for col in score_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    \n",
    "    print(f'\\n{col.upper()}:')\n",
    "    print(f'  Q1 (25%)            : {Q1:.2f}')\n",
    "    print(f'  Q3 (75%)            : {Q3:.2f}')\n",
    "    print(f'  IQR                 : {IQR:.2f}')\n",
    "    print(f'  Borne inférieure    : {lower_bound:.2f}')\n",
    "    print(f'  Borne supérieure    : {upper_bound:.2f}')\n",
    "    print(f'  Valeurs aberrantes  : {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3. Analyse bivariée\n",
    "\n",
    "### 3.1 Corrélations entre les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corrélation\n",
    "correlation_matrix = df[score_cols].corr()\n",
    "\n",
    "print('=== MATRICE DE CORRÉLATION ENTRE LES SCORES ===')\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.3f', square=True, linewidths=1, cbar_kws={'label': 'Corrélation'})\n",
    "plt.title('Heatmap des corrélations entre les scores', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot des scores\n",
    "sns.pairplot(df[score_cols], diag_kind='kde', plot_kws={'alpha': 0.6})\n",
    "plt.suptitle('Pairplot des scores', fontsize=16, fontweight='bold', y=1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Impact du genre sur les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques par genre\n",
    "print('=== SCORES MOYENS PAR GENRE ===')\n",
    "print(df.groupby('gender')[score_cols].mean())\n",
    "\n",
    "print('\\n=== ÉCART-TYPE PAR GENRE ===')\n",
    "print(df.groupby('gender')[score_cols].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation par genre\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, col in enumerate(score_cols):\n",
    "    sns.boxplot(data=df, x='gender', y=col, ax=axes[i], palette='Set2')\n",
    "    axes[i].set_title(f'{col} par genre', fontsize=14, fontweight='bold')\n",
    "    axes[i].set_xlabel('Genre', fontsize=12)\n",
    "    axes[i].set_ylabel('Score', fontsize=12)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Impact du niveau d'éducation des parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques par niveau d'éducation\n",
    "print('=== SCORES MOYENS PAR NIVEAU D\\'ÉDUCATION DES PARENTS ===')\n",
    "print(df.groupby('parental level of education')[score_cols].mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "for i, col in enumerate(score_cols):\n",
    "    sns.boxplot(data=df, x='parental level of education', y=col, ax=axes[i], palette='Set3')\n",
    "    axes[i].set_title(f'{col} par niveau d\\'éducation des parents', fontsize=14, fontweight='bold')\n",
    "    axes[i].set_xlabel('Niveau d\\'éducation', fontsize=12)\n",
    "    axes[i].set_ylabel('Score', fontsize=12)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Impact du type de déjeuner (lunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques par type de lunch\n",
    "print('=== SCORES MOYENS PAR TYPE DE DÉJEUNER ===')\n",
    "print(df.groupby('lunch')[score_cols].mean())\n",
    "\n",
    "print('\\n=== DIFFÉRENCE ENTRE STANDARD ET FREE/REDUCED ===')\n",
    "for col in score_cols:\n",
    "    diff = df[df['lunch']=='standard'][col].mean() - df[df['lunch']=='free/reduced'][col].mean()\n",
    "    print(f'{col}: {diff:.2f} points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, col in enumerate(score_cols):\n",
    "    sns.violinplot(data=df, x='lunch', y=col, ax=axes[i], palette='muted')\n",
    "    axes[i].set_title(f'{col} par type de déjeuner', fontsize=14, fontweight='bold')\n",
    "    axes[i].set_xlabel('Type de déjeuner', fontsize=12)\n",
    "    axes[i].set_ylabel('Score', fontsize=12)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Impact du cours de préparation aux tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques par préparation\n",
    "print('=== SCORES MOYENS PAR COURS DE PRÉPARATION ===')\n",
    "print(df.groupby('test preparation course')[score_cols].mean())\n",
    "\n",
    "print('\\n=== GAIN MOYEN AVEC LE COURS DE PRÉPARATION ===')\n",
    "for col in score_cols:\n",
    "    gain = df[df['test preparation course']=='completed'][col].mean() - df[df['test preparation course']=='none'][col].mean()\n",
    "    print(f'{col}: +{gain:.2f} points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, col in enumerate(score_cols):\n",
    "    sns.boxplot(data=df, x='test preparation course', y=col, ax=axes[i], palette='pastel')\n",
    "    axes[i].set_title(f'{col} par cours de préparation', fontsize=14, fontweight='bold')\n",
    "    axes[i].set_xlabel('Cours de préparation', fontsize=12)\n",
    "    axes[i].set_ylabel('Score', fontsize=12)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Impact de l'origine ethnique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques par groupe ethnique\n",
    "print('=== SCORES MOYENS PAR GROUPE ETHNIQUE ===')\n",
    "print(df.groupby('race/ethnicity')[score_cols].mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "for i, col in enumerate(score_cols):\n",
    "    sns.boxplot(data=df, x='race/ethnicity', y=col, ax=axes[i], palette='husl')\n",
    "    axes[i].set_title(f'{col} par groupe ethnique', fontsize=14, fontweight='bold')\n",
    "    axes[i].set_xlabel('Groupe ethnique', fontsize=12)\n",
    "    axes[i].set_ylabel('Score', fontsize=12)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## 4. Analyse multivariée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse combinée : Genre + Cours de préparation\n",
    "print('=== IMPACT COMBINÉ : GENRE + COURS DE PRÉPARATION ===')\n",
    "print(df.groupby(['gender', 'test preparation course'])[score_cols].mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation combinée\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, col in enumerate(score_cols):\n",
    "    sns.barplot(data=df, x='gender', y=col, hue='test preparation course', ax=axes[i], palette='Set1')\n",
    "    axes[i].set_title(f'{col} - Genre x Préparation', fontsize=14, fontweight='bold')\n",
    "    axes[i].set_xlabel('Genre', fontsize=12)\n",
    "    axes[i].set_ylabel('Score moyen', fontsize=12)\n",
    "    axes[i].legend(title='Préparation')\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse combinée : Lunch + Cours de préparation\n",
    "print('=== IMPACT COMBINÉ : TYPE DE DÉJEUNER + COURS DE PRÉPARATION ===')\n",
    "print(df.groupby(['lunch', 'test preparation course'])[score_cols].mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, col in enumerate(score_cols):\n",
    "    sns.barplot(data=df, x='lunch', y=col, hue='test preparation course', ax=axes[i], palette='Set2')\n",
    "    axes[i].set_title(f'{col} - Déjeuner x Préparation', fontsize=14, fontweight='bold')\n",
    "    axes[i].set_xlabel('Type de déjeuner', fontsize=12)\n",
    "    axes[i].set_ylabel('Score moyen', fontsize=12)\n",
    "    axes[i].legend(title='Préparation')\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de nouvelles features\n",
    "df['total_score'] = df['math score'] + df['reading score'] + df['writing score']\n",
    "df['average_score'] = df['total_score'] / 3\n",
    "\n",
    "# Catégories de performance\n",
    "def categorize_performance(score):\n",
    "    if score >= 80:\n",
    "        return 'Excellent'\n",
    "    elif score >= 70:\n",
    "        return 'Bien'\n",
    "    elif score >= 60:\n",
    "        return 'Moyen'\n",
    "    elif score >= 50:\n",
    "        return 'Passable'\n",
    "    else:\n",
    "        return 'Faible'\n",
    "\n",
    "df['performance_category'] = df['average_score'].apply(categorize_performance)\n",
    "\n",
    "# Score le plus élevé\n",
    "df['best_subject'] = df[score_cols].idxmax(axis=1).str.replace(' score', '')\n",
    "\n",
    "# Score le plus faible\n",
    "df['worst_subject'] = df[score_cols].idxmin(axis=1).str.replace(' score', '')\n",
    "\n",
    "print('Nouvelles features créées :')\n",
    "print('  - total_score')\n",
    "print('  - average_score')\n",
    "print('  - performance_category')\n",
    "print('  - best_subject')\n",
    "print('  - worst_subject')\n",
    "print('\\nAperçu des nouvelles colonnes :')\n",
    "df[['total_score', 'average_score', 'performance_category', 'best_subject', 'worst_subject']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des catégories de performance\n",
    "print('=== DISTRIBUTION DES CATÉGORIES DE PERFORMANCE ===')\n",
    "print(df['performance_category'].value_counts())\n",
    "print('\\nEn pourcentage :')\n",
    "print(df['performance_category'].value_counts(normalize=True).mul(100).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des nouvelles features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Score total\n",
    "axes[0, 0].hist(df['total_score'], bins=30, edgecolor='black', alpha=0.7, color='lightcoral')\n",
    "axes[0, 0].axvline(df['total_score'].mean(), color='red', linestyle='--', linewidth=2,\n",
    "                   label=f'Moyenne: {df[\"total_score\"].mean():.1f}')\n",
    "axes[0, 0].set_title('Distribution du score total', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Score total', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Fréquence', fontsize=12)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Catégories de performance\n",
    "perf_counts = df['performance_category'].value_counts()\n",
    "colors = ['#2ecc71', '#3498db', '#f39c12', '#e74c3c', '#95a5a6']\n",
    "axes[0, 1].bar(range(len(perf_counts)), perf_counts.values, color=colors, edgecolor='black')\n",
    "axes[0, 1].set_xticks(range(len(perf_counts)))\n",
    "axes[0, 1].set_xticklabels(perf_counts.index, rotation=45)\n",
    "axes[0, 1].set_title('Distribution des catégories de performance', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Effectif', fontsize=12)\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Meilleure matière\n",
    "best_counts = df['best_subject'].value_counts()\n",
    "axes[1, 0].bar(range(len(best_counts)), best_counts.values, color='steelblue', edgecolor='black')\n",
    "axes[1, 0].set_xticks(range(len(best_counts)))\n",
    "axes[1, 0].set_xticklabels(best_counts.index, rotation=45)\n",
    "axes[1, 0].set_title('Matière avec le meilleur score', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Nombre d\\'étudiants', fontsize=12)\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pire matière\n",
    "worst_counts = df['worst_subject'].value_counts()\n",
    "axes[1, 1].bar(range(len(worst_counts)), worst_counts.values, color='coral', edgecolor='black')\n",
    "axes[1, 1].set_xticks(range(len(worst_counts)))\n",
    "axes[1, 1].set_xticklabels(worst_counts.index, rotation=45)\n",
    "axes[1, 1].set_title('Matière avec le score le plus faible', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Nombre d\\'étudiants', fontsize=12)\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "## 6. Conclusions et insights\n",
    "\n",
    "### 6.1 Résumé des découvertes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('RÉSUMÉ EXÉCUTIF - INSIGHTS CLÉS')\n",
    "print('='*80)\n",
    "\n",
    "print('\\n1. QUALITÉ DES DONNÉES')\n",
    "print(f'   • Dataset propre : {df.isnull().sum().sum()} valeurs manquantes, {df.duplicated().sum()} doublons')\n",
    "print(f'   • {len(df)} étudiants, {len(categorical_cols)} variables catégorielles, {len(score_cols)} scores')\n",
    "\n",
    "print('\\n2. SCORES MOYENS')\n",
    "for col in score_cols:\n",
    "    print(f'   • {col}: {df[col].mean():.2f} ± {df[col].std():.2f}')\n",
    "print(f'   • Les maths sont la matière la plus faible en moyenne')\n",
    "\n",
    "print('\\n3. IMPACT DU GENRE')\n",
    "print(f'   • Femmes meilleures en lecture/écriture')\n",
    "print(f'   • Hommes légèrement meilleurs en maths')\n",
    "female_math = df[df['gender']=='female']['math score'].mean()\n",
    "male_math = df[df['gender']=='male']['math score'].mean()\n",
    "print(f'   • Écart maths: {abs(male_math - female_math):.2f} points')\n",
    "\n",
    "print('\\n4. IMPACT DE L\\'ÉDUCATION PARENTALE')\n",
    "edu_impact = df.groupby('parental level of education')['average_score'].mean()\n",
    "print(f'   • Meilleur niveau: {edu_impact.idxmax()} ({edu_impact.max():.2f})')\n",
    "print(f'   • Niveau le plus bas: {edu_impact.idxmin()} ({edu_impact.min():.2f})')\n",
    "print(f'   • Différence: {edu_impact.max() - edu_impact.min():.2f} points')\n",
    "\n",
    "print('\\n5. IMPACT DU TYPE DE DÉJEUNER')\n",
    "standard_avg = df[df['lunch']=='standard']['average_score'].mean()\n",
    "reduced_avg = df[df['lunch']=='free/reduced']['average_score'].mean()\n",
    "print(f'   • Standard: {standard_avg:.2f}')\n",
    "print(f'   • Free/Reduced: {reduced_avg:.2f}')\n",
    "print(f'   • Différence: {standard_avg - reduced_avg:.2f} points')\n",
    "print(f'   • Indicateur socio-économique fort')\n",
    "\n",
    "print('\\n6. IMPACT DU COURS DE PRÉPARATION')\n",
    "prep_yes = df[df['test preparation course']=='completed']['average_score'].mean()\n",
    "prep_no = df[df['test preparation course']=='none']['average_score'].mean()\n",
    "print(f'   • Avec préparation: {prep_yes:.2f}')\n",
    "print(f'   • Sans préparation: {prep_no:.2f}')\n",
    "print(f'   • Gain moyen: +{prep_yes - prep_no:.2f} points')\n",
    "\n",
    "print('\\n7. CORRÉLATIONS')\n",
    "print(f'   • Math-Reading: {df[\"math score\"].corr(df[\"reading score\"]):.3f}')\n",
    "print(f'   • Math-Writing: {df[\"math score\"].corr(df[\"writing score\"]):.3f}')\n",
    "print(f'   • Reading-Writing: {df[\"reading score\"].corr(df[\"writing score\"]):.3f}')\n",
    "print(f'   • Reading et Writing très corrélés')\n",
    "\n",
    "print('\\n8. PERFORMANCE GLOBALE')\n",
    "print(df['performance_category'].value_counts())\n",
    "excellent_pct = (df['performance_category']=='Excellent').sum() / len(df) * 100\n",
    "print(f'   • {excellent_pct:.1f}% des étudiants en catégorie \"Excellent\"')\n",
    "\n",
    "print('\\n' + '='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Recommandations pour la modélisation\n",
    "\n",
    "**Variables importantes à considérer:**\n",
    "1. test preparation course - Impact fort (environ +5 points en moyenne)\n",
    "2. lunch - Indicateur socio-économique puissant\n",
    "3. parental level of education - Corrélé avec la réussite\n",
    "4. gender - Impact différencié selon la matière\n",
    "5. race/ethnicity - À utiliser avec précaution\n",
    "\n",
    "**Features engineered utiles:**\n",
    "- average_score - Pour prédiction globale\n",
    "- total_score - Peut capturer des patterns\n",
    "- Interactions entre variables (genre × préparation, lunch × préparation)\n",
    "\n",
    "**Encodage nécessaire:**\n",
    "- One-Hot Encoding pour les variables catégorielles\n",
    "- Standardisation des scores si nécessaire\n",
    "\n",
    "**Algorithmes recommandés:**\n",
    "- Régression linéaire (baseline)\n",
    "- Random Forest (capture interactions)\n",
    "- XGBoost (performance optimale)\n",
    "- Neural Networks (si assez de données)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
