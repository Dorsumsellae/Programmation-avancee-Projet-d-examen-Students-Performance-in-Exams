{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b2b31ee",
   "metadata": {},
   "source": [
    "# 05 - Hyperparameter Tuning (classification)\n",
    "\n",
    "Objectif : optimiser les modèles de classification pour la seule cible **exam passed** (priorité rappel de la classe \"fail\") via GridSearchCV, RandomizedSearchCV et Optuna, comparer aux baselines et sauvegarder le meilleur modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f438d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\anaconda3\\envs\\Data\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, f1_score, accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.base import clone\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae31cb38",
   "metadata": {},
   "source": [
    "## 1. Charger et préparer les données\n",
    "- Chargement `data/processed/train.csv` et `test.csv`\n",
    "- Drop des colonnes d'index sauvegardées\n",
    "- Cible unique : `exam passed`; features catégorielles socio-démo\n",
    "- Préprocessing : OneHotEncoder pour toutes les features cat (éviter l'ordinalité)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a409b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & data loading\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "RANDOM_STATE = 42\n",
    "CV_SPLITS = 5\n",
    "\n",
    "# Paths\n",
    "train_path = Path('..') / 'data' / 'processed' / 'train.csv'\n",
    "test_path = Path('..') / 'data' / 'processed' / 'test.csv'\n",
    "\n",
    "for p in [train_path, test_path]:\n",
    "    assert p.exists(), f\"Missing file: {p}\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Drop stray index columns\n",
    "cols_to_drop = [c for c in train_df.columns if c.startswith('Unnamed') or c == '']\n",
    "train_df = train_df.drop(columns=cols_to_drop)\n",
    "test_df = test_df.drop(columns=cols_to_drop)\n",
    "\n",
    "base_cols = [\n",
    "    \"gender\",\n",
    "    \"race/ethnicity\",\n",
    "    \"parental level of education\",\n",
    "    \"lunch\",\n",
    "    \"test preparation course\",\n",
    "]\n",
    "\n",
    "tasks = {\n",
    "    \"language\": {\"target\": \"language passed\", \"features\": base_cols},\n",
    "    \"math\": {\"target\": \"math passed\", \"features\": base_cols},\n",
    "    \"exam\": {\"target\": \"exam passed\", \"features\": base_cols},\n",
    "}\n",
    "\n",
    "# Build splits per task (no split train/val here because CV handles it)\n",
    "data_splits = {}\n",
    "for name, spec in tasks.items():\n",
    "    X_train = train_df[spec[\"features\"]]\n",
    "    y_train = train_df[spec[\"target\"]]\n",
    "    X_test = test_df[spec[\"features\"]]\n",
    "    y_test = test_df[spec[\"target\"]]\n",
    "    data_splits[name] = {\"X_train\": X_train, \"y_train\": y_train, \"X_test\": X_test, \"y_test\": y_test}\n",
    "\n",
    "categorical_cols = base_cols\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "recall_fail_scorer = make_scorer(recall_score, pos_label=0)\n",
    "scoring = {\n",
    "    \"recall_fail\": recall_fail_scorer,\n",
    "    \"f1\": \"f1\",\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f556e5f",
   "metadata": {},
   "source": [
    "## 2. Définir le modèle de base\n",
    "Baseline : pipelines simples (LogReg, RF, GBoost, XGB, LGBM, Linear SVM calibré) avec pondération de classe, sur la seule tâche `exam`. Mesure principale : recall_fail (classe 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b239d8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>recall_fail</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [task, model, recall_fail, f1, accuracy, roc_auc]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baselines (option: skip if pretrained models are available)\n",
    "USE_PRETRAINED_EXAM = True\n",
    "\n",
    "\n",
    "def make_models_for_task(y_train):\n",
    "    n_fail = max((y_train == 0).sum(), 1)\n",
    "    n_pass = max((y_train == 1).sum(), 1)\n",
    "    fail_weight = n_pass / n_fail\n",
    "    scale_pos_weight = n_fail / n_pass\n",
    "\n",
    "    return {\n",
    "        \"log_reg\": Pipeline([\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"clf\", LogisticRegression(max_iter=1000, n_jobs=-1, class_weight=\"balanced\", solver=\"lbfgs\")),\n",
    "        ]),\n",
    "        \"rf\": Pipeline([\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"clf\", RandomForestClassifier(n_estimators=400, random_state=RANDOM_STATE, n_jobs=-1, class_weight=\"balanced\")),\n",
    "        ]),\n",
    "        \"gboost\": Pipeline([\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"clf\", GradientBoostingClassifier(random_state=RANDOM_STATE)),\n",
    "        ]),\n",
    "        \"xgb\": Pipeline([\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"clf\", XGBClassifier(\n",
    "                n_estimators=400,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.05,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                eval_metric=\"logloss\",\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=-1,\n",
    "                scale_pos_weight=scale_pos_weight,\n",
    "            )),\n",
    "        ]),\n",
    "        \"lgbm\": Pipeline([\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"clf\", LGBMClassifier(\n",
    "                n_estimators=400,\n",
    "                max_depth=-1,\n",
    "                num_leaves=31,\n",
    "                learning_rate=0.05,\n",
    "                subsample=0.9,\n",
    "                colsample_bytree=0.9,\n",
    "                random_state=RANDOM_STATE,\n",
    "                class_weight={0: fail_weight, 1: 1.0},\n",
    "            )),\n",
    "        ]),\n",
    "        \"linear_svm\": Pipeline([\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"clf\", CalibratedClassifierCV(\n",
    "                estimator=LinearSVC(class_weight=\"balanced\"),\n",
    "                cv=3,\n",
    "                n_jobs=-1,\n",
    "            )),\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "\n",
    "def cv_eval(model, X, y):\n",
    "    cv_res = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "    return {k.replace(\"test_\", \"\"): np.mean(v) for k, v in cv_res.items() if k.startswith(\"test_\")}\n",
    "\n",
    "# Baseline CV (exam only, unless pretrained used)\n",
    "baseline_rows = []\n",
    "baseline_results = {}\n",
    "models_by_task = {}\n",
    "for task, split in data_splits.items():\n",
    "    if USE_PRETRAINED_EXAM:\n",
    "        continue\n",
    "    models = make_models_for_task(split[\"y_train\"])\n",
    "    models_by_task[task] = models\n",
    "    baseline_results[task] = {}\n",
    "    for name, model in models.items():\n",
    "        res = cv_eval(model, split[\"X_train\"], split[\"y_train\"])\n",
    "        baseline_results[task][name] = res\n",
    "        baseline_rows.append({\"task\": task, \"model\": name, **res})\n",
    "\n",
    "if baseline_rows:\n",
    "    baseline_df = pd.DataFrame(baseline_rows).sort_values([\"task\", \"recall_fail\"], ascending=[True, False])\n",
    "else:\n",
    "    baseline_df = pd.DataFrame(columns=[\"task\", \"model\", \"recall_fail\", \"f1\", \"accuracy\", \"roc_auc\"])\n",
    "\n",
    "baseline_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea9043",
   "metadata": {},
   "source": [
    "## 3. GridSearchCV (espace restreint, explicite)\n",
    "- Modèle ciblé : XGBClassifier\n",
    "- Justification : profondeur modérée, lr faible, subsample/colsample pour limiter l’overfit, scale_pos_weight dérivé du ratio classes.\n",
    "- Param_grid (exemple) :\n",
    "  - max_depth: [3, 4, 5]\n",
    "  - learning_rate: [0.02, 0.05, 0.1]\n",
    "  - n_estimators: [200, 400, 600]\n",
    "  - subsample: [0.7, 0.9]\n",
    "  - colsample_bytree: [0.7, 0.9]\n",
    "  - scale_pos_weight: [ratio, ratio*0.7, ratio*1.3] (ratio = n_fail/n_pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd172c9",
   "metadata": {},
   "source": [
    "## 3.1 Utiliser les modèles exam déjà entraînés (04b)\n",
    "Si disponibles dans `models/exam_*.joblib`, on les charge pour éviter de réentraîner la baseline exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39505c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\anaconda3\\envs\\Data\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\nicol\\anaconda3\\envs\\Data\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:131: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] Le fichier spécifié est introuvable\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\nicol\\anaconda3\\envs\\Data\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 247, in _count_physical_cores\n",
      "    cpu_count_physical = _count_physical_cores_win32()\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\anaconda3\\envs\\Data\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 299, in _count_physical_cores_win32\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\anaconda3\\envs\\Data\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\anaconda3\\envs\\Data\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\nicol\\anaconda3\\envs\\Data\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "c:\\Users\\nicol\\anaconda3\\envs\\Data\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall_fail</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exam</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.672065</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.682821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exam</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.646583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exam</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.674603</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.629655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task    model  accuracy        f1  recall_fail   roc_auc\n",
       "1  exam  log_reg     0.595  0.672065     0.654545  0.682821\n",
       "2  exam      xgb     0.615  0.698039     0.618182  0.646583\n",
       "0  exam     lgbm     0.590  0.674603     0.600000  0.629655"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger les modèles exam déjà entraînés (si présents dans models/exam_*.joblib)\n",
    "exam_split = data_splits[\"exam\"]\n",
    "pretrained_exam_rows = []\n",
    "models_dir = Path(\"..\") / \"models\" / \"classification\"\n",
    "if USE_PRETRAINED_EXAM and models_dir.exists():\n",
    "    for path in models_dir.glob(\"exam_*.joblib\"):\n",
    "        model_name = path.stem.replace(\"exam_\", \"\")\n",
    "        model = joblib.load(path)\n",
    "        preds = model.predict(exam_split[\"X_test\"])\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            proba = model.predict_proba(exam_split[\"X_test\"])[:, 1]\n",
    "            auc = roc_auc_score(exam_split[\"y_test\"], proba)\n",
    "        elif hasattr(model, \"decision_function\"):\n",
    "            proba = model.decision_function(exam_split[\"X_test\"])\n",
    "            auc = roc_auc_score(exam_split[\"y_test\"], proba)\n",
    "        else:\n",
    "            proba = None\n",
    "            auc = np.nan\n",
    "        pretrained_exam_rows.append(\n",
    "            {\n",
    "                \"task\": \"exam\",\n",
    "                \"model\": model_name,\n",
    "                \"accuracy\": accuracy_score(exam_split[\"y_test\"], preds),\n",
    "                \"f1\": f1_score(exam_split[\"y_test\"], preds),\n",
    "                \"recall_fail\": recall_score(exam_split[\"y_test\"], preds, pos_label=0),\n",
    "                \"roc_auc\": auc,\n",
    "            }\n",
    "        )\n",
    "\n",
    "pretrained_exam_df = pd.DataFrame(pretrained_exam_rows).sort_values(\"recall_fail\", ascending=False)\n",
    "pretrained_exam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93acb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\anaconda3\\envs\\Data\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:40:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>recall_fail</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_scale_pos_weight</th>\n",
       "      <th>param_subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb_grid</td>\n",
       "      <td>0.807879</td>\n",
       "      <td>0.616588</td>\n",
       "      <td>0.57125</td>\n",
       "      <td>0.710984</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.272222</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  recall_fail        f1  accuracy   roc_auc  \\\n",
       "0  xgb_grid     0.807879  0.616588   0.57125  0.710984   \n",
       "\n",
       "   param_colsample_bytree  param_learning_rate  param_max_depth  \\\n",
       "0                     0.9                 0.02                3   \n",
       "\n",
       "   param_n_estimators  param_scale_pos_weight  param_subsample  \n",
       "0                 200                0.272222              0.9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search XGB (task exam)\n",
    "exam_split = data_splits[\"exam\"]\n",
    "X_exam, y_exam = exam_split[\"X_train\"], exam_split[\"y_train\"]\n",
    "n_fail = max((y_exam == 0).sum(), 1)\n",
    "n_pass = max((y_exam == 1).sum(), 1)\n",
    "fail_pass_ratio = n_fail / n_pass\n",
    "\n",
    "xgb_base = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\n",
    "        \"clf\",\n",
    "        XGBClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            eval_metric=\"logloss\",\n",
    "            n_jobs=-1,\n",
    "            use_label_encoder=False,\n",
    "            scale_pos_weight=fail_pass_ratio,\n",
    "        ),\n",
    "    ),\n",
    "])\n",
    "\n",
    "xgb_param_grid = {\n",
    "    \"clf__max_depth\": [3, 4, 5],\n",
    "    \"clf__learning_rate\": [0.02, 0.05, 0.1],\n",
    "    \"clf__n_estimators\": [200, 400, 600],\n",
    "    \"clf__subsample\": [0.7, 0.9],\n",
    "    \"clf__colsample_bytree\": [0.7, 0.9],\n",
    "    \"clf__scale_pos_weight\": [fail_pass_ratio * f for f in [0.7, 1.0, 1.3]],\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    xgb_base,\n",
    "    xgb_param_grid,\n",
    "    scoring=scoring,\n",
    "    refit=\"recall_fail\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_xgb.fit(X_exam, y_exam)\n",
    "\n",
    "def extract_best_scores(search):\n",
    "    idx = search.best_index_\n",
    "    res = search.cv_results_\n",
    "    return {\n",
    "        \"recall_fail\": res[\"mean_test_recall_fail\"][idx],\n",
    "        \"f1\": res[\"mean_test_f1\"][idx],\n",
    "        \"accuracy\": res[\"mean_test_accuracy\"][idx],\n",
    "        \"roc_auc\": res[\"mean_test_roc_auc\"][idx],\n",
    "    }\n",
    "\n",
    "xgb_grid_scores = extract_best_scores(grid_xgb)\n",
    "pd.DataFrame([\n",
    "    {\"model\": \"xgb_grid\", **xgb_grid_scores, **{k.replace(\"clf__\", \"param_\"): v for k, v in grid_xgb.best_params_.items()}},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b58bb9c",
   "metadata": {},
   "source": [
    "## 4. RandomizedSearchCV (espace plus large)\n",
    "- Modèle ciblé : LGBMClassifier\n",
    "- Justification : balayage plus large via distributions continues pour lr/subsample/colsample et discrètes pour num_leaves/n_estimators.\n",
    "- n_iter modéré pour rester raisonnable en temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af55c9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Number of positive: 576, number of negative: 224\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>recall_fail</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>param_subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm_random</td>\n",
       "      <td>0.585152</td>\n",
       "      <td>0.728651</td>\n",
       "      <td>0.64375</td>\n",
       "      <td>0.675257</td>\n",
       "      <td>0.673362</td>\n",
       "      <td>0.065636</td>\n",
       "      <td>4</td>\n",
       "      <td>452</td>\n",
       "      <td>58</td>\n",
       "      <td>0.609225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  recall_fail        f1  accuracy   roc_auc  \\\n",
       "0  lgbm_random     0.585152  0.728651   0.64375  0.675257   \n",
       "\n",
       "   param_colsample_bytree  param_learning_rate  param_max_depth  \\\n",
       "0                0.673362             0.065636                4   \n",
       "\n",
       "   param_n_estimators  param_num_leaves  param_subsample  \n",
       "0                 452                58         0.609225  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomized search LGBM (task exam)\n",
    "fail_weight = n_pass / n_fail\n",
    "\n",
    "lgbm_base = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\n",
    "        \"clf\",\n",
    "        LGBMClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            class_weight={0: fail_weight, 1: 1.0},\n",
    "            n_jobs=-1,\n",
    "        ),\n",
    "    ),\n",
    "])\n",
    "\n",
    "lgbm_param_dist = {\n",
    "    \"clf__num_leaves\": randint(15, 64),\n",
    "    \"clf__max_depth\": [-1, 4, 6, 8],\n",
    "    \"clf__learning_rate\": uniform(0.02, 0.15),\n",
    "    \"clf__n_estimators\": randint(200, 601),\n",
    "    \"clf__subsample\": uniform(0.6, 0.4),\n",
    "    \"clf__colsample_bytree\": uniform(0.6, 0.4),\n",
    "}\n",
    "\n",
    "rand_lgbm = RandomizedSearchCV(\n",
    "    lgbm_base,\n",
    "    lgbm_param_dist,\n",
    "    n_iter=10,\n",
    "    scoring=scoring,\n",
    "    refit=\"recall_fail\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "rand_lgbm.fit(X_exam, y_exam)\n",
    "\n",
    "lgbm_rand_scores = extract_best_scores(rand_lgbm)\n",
    "pd.DataFrame([\n",
    "    {\"model\": \"lgbm_random\", **lgbm_rand_scores, **{k.replace(\"clf__\", \"param_\"): v for k, v in rand_lgbm.best_params_.items()}},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc6385",
   "metadata": {},
   "source": [
    "## 5. Optuna (TPE, priorité recall_fail)\n",
    "- TPE sampler avec graine fixe.\n",
    "- Même préprocessing OneHot; cible = exam.\n",
    "- Objectif : maximiser le recall de la classe \"fail\" via validation croisée.\n",
    "- Espace : profondeur, lr, n_estimators, subsample, colsample, min_child_weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5c13140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-07 14:44:38,276] A new study created in memory with name: no-name-2a7dacf6-e593-4403-b4a2-ec0839f13aff\n",
      "[I 2026-01-07 14:44:38,682] Trial 0 finished with value: 0.576060606060606 and parameters: {'max_depth': 4, 'learning_rate': 0.1358198535217987, 'n_estimators': 566, 'subsample': 0.8095304694689628, 'colsample_bytree': 0.6546065241548528, 'min_child_weight': 1.201975341512912}. Best is trial 0 with value: 0.576060606060606.\n",
      "[I 2026-01-07 14:44:38,947] Trial 1 finished with value: 0.5984848484848484 and parameters: {'max_depth': 3, 'learning_rate': 0.11454791487656053, 'n_estimators': 501, 'subsample': 0.8478254022286159, 'colsample_bytree': 0.6072045730035308, 'min_child_weight': 4.864594334728975}. Best is trial 1 with value: 0.5984848484848484.\n",
      "[I 2026-01-07 14:44:39,190] Trial 2 finished with value: 0.5895959595959597 and parameters: {'max_depth': 6, 'learning_rate': 0.030678895924589226, 'n_estimators': 291, 'subsample': 0.6641915784487018, 'colsample_bytree': 0.7064847850358382, 'min_child_weight': 2.86140394234507}. Best is trial 1 with value: 0.5984848484848484.\n",
      "[I 2026-01-07 14:44:39,385] Trial 3 finished with value: 0.602929292929293 and parameters: {'max_depth': 4, 'learning_rate': 0.03596444270828742, 'n_estimators': 506, 'subsample': 0.6488228512282146, 'colsample_bytree': 0.7022506269873263, 'min_child_weight': 2.148628294821613}. Best is trial 3 with value: 0.602929292929293.\n",
      "[I 2026-01-07 14:44:39,465] Trial 4 finished with value: 0.5806060606060606 and parameters: {'max_depth': 4, 'learning_rate': 0.09729870597990298, 'n_estimators': 300, 'subsample': 0.779982053444764, 'colsample_bytree': 0.8073450991017148, 'min_child_weight': 0.7090268572399898}. Best is trial 3 with value: 0.602929292929293.\n",
      "[I 2026-01-07 14:44:39,522] Trial 5 finished with value: 0.6073737373737373 and parameters: {'max_depth': 5, 'learning_rate': 0.028199996263578355, 'n_estimators': 232, 'subsample': 0.9321099380386666, 'colsample_bytree': 0.9379712115760958, 'min_child_weight': 4.137788066524076}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:39,621] Trial 6 finished with value: 0.602929292929293 and parameters: {'max_depth': 4, 'learning_rate': 0.02435000636897718, 'n_estimators': 542, 'subsample': 0.7540533728088604, 'colsample_bytree': 0.6427133821956725, 'min_child_weight': 2.728296095500716}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:39,679] Trial 7 finished with value: 0.6029292929292929 and parameters: {'max_depth': 3, 'learning_rate': 0.12495137958834718, 'n_estimators': 329, 'subsample': 0.8318827995238937, 'colsample_bytree': 0.7090988766312938, 'min_child_weight': 2.8403060953001487}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:39,799] Trial 8 finished with value: 0.5895959595959597 and parameters: {'max_depth': 5, 'learning_rate': 0.02902611884153732, 'n_estimators': 685, 'subsample': 0.87129648817639, 'colsample_bytree': 0.9288246295474661, 'min_child_weight': 4.526723076924419}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:39,856] Trial 9 finished with value: 0.5851515151515152 and parameters: {'max_depth': 5, 'learning_rate': 0.12815230690684767, 'n_estimators': 244, 'subsample': 0.6685940018467008, 'colsample_bytree': 0.6158295511186883, 'min_child_weight': 1.9639864884346896}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:39,949] Trial 10 finished with value: 0.5895959595959596 and parameters: {'max_depth': 6, 'learning_rate': 0.051906339094279705, 'n_estimators': 384, 'subsample': 0.9343006901645645, 'colsample_bytree': 0.9443636823971141, 'min_child_weight': 4.02069771449068}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:40,053] Trial 11 finished with value: 0.5894949494949495 and parameters: {'max_depth': 5, 'learning_rate': 0.044101191105017666, 'n_estimators': 420, 'subsample': 0.6046118563621692, 'colsample_bytree': 0.8322464849214934, 'min_child_weight': 3.637201542530425}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:40,146] Trial 12 finished with value: 0.603030303030303 and parameters: {'max_depth': 4, 'learning_rate': 0.03603765775262973, 'n_estimators': 215, 'subsample': 0.9305112277060715, 'colsample_bytree': 0.8656916154105891, 'min_child_weight': 1.8975868848036357}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:40,262] Trial 13 finished with value: 0.5984848484848484 and parameters: {'max_depth': 5, 'learning_rate': 0.02047466709777101, 'n_estimators': 232, 'subsample': 0.9497312988781559, 'colsample_bytree': 0.8724411876090038, 'min_child_weight': 3.545681261430267}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:40,378] Trial 14 finished with value: 0.5852525252525252 and parameters: {'max_depth': 6, 'learning_rate': 0.03826614739922507, 'n_estimators': 201, 'subsample': 0.9061488911696365, 'colsample_bytree': 0.8851630468843157, 'min_child_weight': 1.5871679382337391}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:40,479] Trial 15 finished with value: 0.5941414141414141 and parameters: {'max_depth': 3, 'learning_rate': 0.07893747499193082, 'n_estimators': 371, 'subsample': 0.8928253648133213, 'colsample_bytree': 0.8885395676270214, 'min_child_weight': 2.300748684857557}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:40,563] Trial 16 finished with value: 0.602929292929293 and parameters: {'max_depth': 4, 'learning_rate': 0.05420702893277421, 'n_estimators': 269, 'subsample': 0.7306404201289891, 'colsample_bytree': 0.7837222086971325, 'min_child_weight': 3.4252657933979505}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:40,690] Trial 17 finished with value: 0.5361616161616162 and parameters: {'max_depth': 5, 'learning_rate': 0.07110766127518225, 'n_estimators': 360, 'subsample': 0.9166560427868511, 'colsample_bytree': 0.8497732374070607, 'min_child_weight': 0.540693879509553}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:40,838] Trial 18 finished with value: 0.5895959595959596 and parameters: {'max_depth': 5, 'learning_rate': 0.026363865239131257, 'n_estimators': 680, 'subsample': 0.8639841613038968, 'colsample_bytree': 0.9179010933234169, 'min_child_weight': 4.222835722231081}. Best is trial 5 with value: 0.6073737373737373.\n",
      "[I 2026-01-07 14:44:40,910] Trial 19 finished with value: 0.6162626262626263 and parameters: {'max_depth': 4, 'learning_rate': 0.020351077195982184, 'n_estimators': 200, 'subsample': 0.8190992736892638, 'colsample_bytree': 0.9055162579457247, 'min_child_weight': 1.3236485128269826}. Best is trial 19 with value: 0.6162626262626263.\n",
      "[I 2026-01-07 14:44:41,059] Trial 20 finished with value: 0.5985858585858586 and parameters: {'max_depth': 6, 'learning_rate': 0.02112750977378095, 'n_estimators': 426, 'subsample': 0.8011854096885552, 'colsample_bytree': 0.7526721598629622, 'min_child_weight': 1.2891314912058847}. Best is trial 19 with value: 0.6162626262626263.\n",
      "[I 2026-01-07 14:44:41,134] Trial 21 finished with value: 0.5941414141414142 and parameters: {'max_depth': 4, 'learning_rate': 0.03383933738063625, 'n_estimators': 209, 'subsample': 0.884897796952241, 'colsample_bytree': 0.9081596055501858, 'min_child_weight': 1.6260635674745223}. Best is trial 19 with value: 0.6162626262626263.\n",
      "[I 2026-01-07 14:44:41,229] Trial 22 finished with value: 0.594040404040404 and parameters: {'max_depth': 4, 'learning_rate': 0.024564330295708963, 'n_estimators': 258, 'subsample': 0.7248463893978248, 'colsample_bytree': 0.9428806902356287, 'min_child_weight': 0.9417664159205674}. Best is trial 19 with value: 0.6162626262626263.\n",
      "[I 2026-01-07 14:44:41,316] Trial 23 finished with value: 0.602929292929293 and parameters: {'max_depth': 3, 'learning_rate': 0.04327110263397471, 'n_estimators': 314, 'subsample': 0.9242689634229627, 'colsample_bytree': 0.8582784121416156, 'min_child_weight': 2.494905609962316}. Best is trial 19 with value: 0.6162626262626263.\n",
      "[I 2026-01-07 14:44:41,391] Trial 24 finished with value: 0.602929292929293 and parameters: {'max_depth': 4, 'learning_rate': 0.030100641165896443, 'n_estimators': 203, 'subsample': 0.826228643489303, 'colsample_bytree': 0.824967909070069, 'min_child_weight': 1.7796208408350058}. Best is trial 19 with value: 0.6162626262626263.\n",
      "c:\\Users\\nicol\\anaconda3\\envs\\Data\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:44:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>recall_fail</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>optuna_xgb</td>\n",
       "      <td>0.616263</td>\n",
       "      <td>0.751097</td>\n",
       "      <td>0.67125</td>\n",
       "      <td>0.709284</td>\n",
       "      <td>4</td>\n",
       "      <td>0.020351</td>\n",
       "      <td>200</td>\n",
       "      <td>0.819099</td>\n",
       "      <td>0.905516</td>\n",
       "      <td>1.323649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  recall_fail        f1  accuracy   roc_auc  param_max_depth  \\\n",
       "0  optuna_xgb     0.616263  0.751097   0.67125  0.709284                4   \n",
       "\n",
       "   param_learning_rate  param_n_estimators  param_subsample  \\\n",
       "0             0.020351                 200         0.819099   \n",
       "\n",
       "   param_colsample_bytree  param_min_child_weight  \n",
       "0                0.905516                1.323649  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optuna search (XGB) on exam\n",
    "exam_split = data_splits[\"exam\"]\n",
    "X_exam, y_exam = exam_split[\"X_train\"], exam_split[\"y_train\"]\n",
    "n_fail = max((y_exam == 0).sum(), 1)\n",
    "n_pass = max((y_exam == 1).sum(), 1)\n",
    "fail_pass_ratio = n_fail / n_pass\n",
    "\n",
    "\n",
    "def build_xgb_with_params(params):\n",
    "    return Pipeline(\n",
    "        [\n",
    "            (\"prep\", preprocessor),\n",
    "            (\n",
    "                \"clf\",\n",
    "                XGBClassifier(\n",
    "                    random_state=RANDOM_STATE,\n",
    "                    eval_metric=\"logloss\",\n",
    "                    n_jobs=-1,\n",
    "                    use_label_encoder=False,\n",
    "                    scale_pos_weight=fail_pass_ratio,\n",
    "                    **params,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 6),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.15, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 700),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.95),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.95),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0.5, 5.0),\n",
    "    }\n",
    "    model = build_xgb_with_params(params)\n",
    "    cv_res = cross_validate(\n",
    "        model,\n",
    "        X_exam,\n",
    "        y_exam,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "    return np.mean(cv_res[\"test_recall_fail\"])\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(objective, n_trials=25, show_progress_bar=False)\n",
    "\n",
    "optuna_best_params = study.best_params\n",
    "optuna_best_recall = study.best_value\n",
    "optuna_best_estimator = build_xgb_with_params(optuna_best_params)\n",
    "\n",
    "# CV metrics on best estimator (for comparison table)\n",
    "optuna_cv_scores = cv_eval(optuna_best_estimator, X_exam, y_exam)\n",
    "\n",
    "# Fit best estimator on full exam train for downstream test eval\n",
    "optuna_best_estimator.fit(X_exam, y_exam)\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"model\": \"optuna_xgb\", **optuna_cv_scores, **{f\"param_{k}\": v for k, v in optuna_best_params.items()}},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a57057",
   "metadata": {},
   "source": [
    "## 6. Comparaison baselines vs modèles tunés (CV)\n",
    "- Agrégation des scores CV (recall_fail prioritaire).\n",
    "- Sélection du meilleur modèle tuned sur la tâche exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d7ddc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall_fail</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exam</td>\n",
       "      <td>xgb_grid</td>\n",
       "      <td>0.57125</td>\n",
       "      <td>0.616588</td>\n",
       "      <td>0.807879</td>\n",
       "      <td>0.710984</td>\n",
       "      <td>tuned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exam</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.59500</td>\n",
       "      <td>0.672065</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.682821</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exam</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.61500</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.646583</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exam</td>\n",
       "      <td>optuna_xgb</td>\n",
       "      <td>0.67125</td>\n",
       "      <td>0.751097</td>\n",
       "      <td>0.616263</td>\n",
       "      <td>0.709284</td>\n",
       "      <td>tuned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exam</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.59000</td>\n",
       "      <td>0.674603</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.629655</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exam</td>\n",
       "      <td>lgbm_random</td>\n",
       "      <td>0.64375</td>\n",
       "      <td>0.728651</td>\n",
       "      <td>0.585152</td>\n",
       "      <td>0.675257</td>\n",
       "      <td>tuned</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task        model  accuracy        f1  recall_fail   roc_auc      type\n",
       "3  exam     xgb_grid   0.57125  0.616588     0.807879  0.710984     tuned\n",
       "0  exam      log_reg   0.59500  0.672065     0.654545  0.682821  baseline\n",
       "1  exam          xgb   0.61500  0.698039     0.618182  0.646583  baseline\n",
       "5  exam   optuna_xgb   0.67125  0.751097     0.616263  0.709284     tuned\n",
       "2  exam         lgbm   0.59000  0.674603     0.600000  0.629655  baseline\n",
       "4  exam  lgbm_random   0.64375  0.728651     0.585152  0.675257     tuned"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_search(name, search):\n",
    "    scores = extract_best_scores(search)\n",
    "    return {\"task\": \"exam\", \"model\": name, **scores}\n",
    "\n",
    "# Baseline exam source: pretrained if available; otherwise CV baseline if present\n",
    "if USE_PRETRAINED_EXAM and not pretrained_exam_df.empty:\n",
    "    exam_baseline = pretrained_exam_df.copy()\n",
    "elif (not USE_PRETRAINED_EXAM) and (not baseline_df.empty):\n",
    "    exam_baseline = baseline_df.copy()\n",
    "else:\n",
    "    exam_baseline = pd.DataFrame(columns=[\"task\", \"model\", \"recall_fail\", \"f1\", \"accuracy\", \"roc_auc\"])\n",
    "\n",
    "if exam_baseline.empty:\n",
    "    print(\"Aucun baseline exam disponible : vérifiez models/exam_*.joblib ou relancez le CV baseline.\")\n",
    "\n",
    "optuna_row = {\"task\": \"exam\", \"model\": \"optuna_xgb\", **optuna_cv_scores}\n",
    "\n",
    "tuned_rows = [\n",
    "    summarize_search(\"xgb_grid\", grid_xgb),\n",
    "    summarize_search(\"lgbm_random\", rand_lgbm),\n",
    "    optuna_row,\n",
    "]\n",
    "tuned_df = pd.DataFrame(tuned_rows)\n",
    "\n",
    "comparison_df = pd.concat(\n",
    "    [exam_baseline.assign(type=\"baseline\"), tuned_df.assign(type=\"tuned\")],\n",
    "    ignore_index=True,\n",
    ")\n",
    "comparison_df.sort_values(\"recall_fail\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecca4de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABXQAAAHvCAYAAAD0G1dRAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfbtJREFUeJzs3XmcjfX7x/H3nDMLYxuyb2UdDYZhGCSaoVT2LSSlrCkxEkr2JUTWTNaK9FXWSCrZRSNSkZDdYMYu6yxn7t8ffk5mxjDDnDlzn3k9H495PObc2+e67nPOXOdcc5/PcTMMwxAAAAAAAAAAIMOzODsAAAAAAAAAAEDK0NAFAAAAAAAAAJOgoQsAAAAAAAAAJkFDFwAAAAAAAABMgoYuAAAAAAAAAJgEDV0AAAAAAAAAMAkaugAAAAAAAABgEjR0AQAAAAAAAMAkaOgCAAAATmQYhrNDAAAAgInQ0AUAAJlChw4d5Ovrm+AnMDBQL7/8srZv3+60uHx9fTV16lRJUnh4uHx9fRUeHu60eFxNRESEfH19tXTp0gTL58yZI19fX61atequ+915vzhSWFiY5syZ4/BxvvzyS/n6+uqbb75Js2P+8MMPateuXYJl8fHxWrRokdq3b6+goCBVqVJFzZs317x58xQTEyNJunHjhqpWraquXbsme+wLFy6oQoUK+vDDDyVJ7dq10+rVq9MsdgAAADNzd3YAAAAA6cXPz09DhgyRJNlsNl28eFH/+9//1KlTJy1dulRlypRxanzly5fXV199pdKlSzs1jsygU6dOOnnypKZNm6bnnntOFotzrnOYNGmS3nzzTYeOERMTo1mzZql79+5q2rRpmhzzwoULGjZsmGbOnGlfduPGDXXv3l1//PGH2rVrp86dO8vDw0Ph4eEaP368Nm7cqLCwMGXNmlUNGzbUkiVLdOHCBeXJkyfJ8b/99lvFxsaqZcuWkqSBAweqa9euql69uh555JE0yQEAAMCsaOgCAIBMI3v27KpcuXKCZbVq1VLNmjW1dOlS9e/f3zmB/b+7xQfHef/993XkyBHZbDanNXTTy5w5c1SiRIk0O9706dNVvnx5VahQwb7sgw8+0G+//ab58+cneBzXrl1bfn5+6t27txYsWKBXX31VrVq10ldffaXvvvtOL730UpLjL1++XIGBgSpZsqQkqUKFCipfvrzCwsL0/vvvp1keAAAAZuTar1wBAADuI2vWrPLy8pKbm5t9mc1m08yZM9WoUSP5+/urcuXKatu2rbZt22bfJjo6WsOGDVOdOnVUoUIFPfvss5o7d26CY1+6dEmDBw9WrVq1VLFiRb3wwgsJjpFY4ikXpk6dqqefflobNmxQ48aNVaFCBTVo0EDLli1L9Thbt25VmzZtFBAQoGrVqqlHjx46fPhwsrE0aNBAb7zxRpLlrVu3tn9U/sSJE3r99dcVFBSkSpUqqU2bNtq4cWOyx5SkkJAQTZs2TR988IGCgoIUEBCgt99+W9euXdPMmTNVp04dVa1aVT179tTFixft+9lsNi1YsECNGzeWv7+/nnrqKY0fP17R0dEJjv/jjz+qSZMm8vf3V/PmzbVv374kMdw+X7Vr11azZs3Uvn37e94vd+6TlufY19dXkjRt2jT771OnTrX/nnjb21NA3J5GYvXq1Xrrrbfs4w0cOFDXrl1LsN+iRYvUvHlzNWnSRMHBwZo6dari4uLs6y9cuKC+ffvqiSeeUMWKFdW0aVMtX778nufiwoULWrx4sRo3bpxg2ZIlS9SyZcu7/lPiueeeU6dOnVSwYEFJkr+/v8qWLauVK1cm2faff/7RX3/9pdatWydY3qRJEy1evFgXLly4Z3wAAACujoYuAADINAzDUFxcnOLi4hQbG6uzZ8/qo48+UkxMjP2j3ZI0fvx4ffzxx2rTpo1mz56t4cOH6+LFi+rVq5euX78uSRo1apQ2btyo/v37a86cOapXr57Gjh1rn6s1Ojpar7zyitauXavQ0FBNmzZNBQsWVOfOne/bPLzT2bNnNXz4cL388suaOXOmihYtqgEDBujQoUMpHud24/X2FY4jR47U4cOH1bVrV8XHx9913KZNm2rTpk26evWqfdnx48f1559/qmnTpoqPj1e3bt10/fp1jRs3TtOnT5ePj4969OihY8eO3TOnTz/9VKdOndLEiRPVvXt3ffvtt2rZsqV+/vlnjRgxQj179tTatWs1ZcoU+z6DBw/W6NGjFRISorCwMLVv315ffPGFevToYf9SsXXr1umtt95SmTJl7FMpvPPOOwnGfpD7xVHn+KuvvpIk+9WqqTVkyBAVKVJE06dPV+fOnbVkyRJ98skn9vUzZszQoEGDVLNmTX3yySdq3769Zs2apcGDB9u3eeedd3Tw4EH79Al+fn7q37//Pedx/vHHHxUXF6d69erZl23btk1xcXEKDg5Odr9+/frpueees99u2bKlfv/9dx0/fjzBdsuWLVP27NnVoEGDBMvr1asnm82mNWvW3P/kAAAAuDCmXAAAAJnGr7/+qvLlyydZ3qdPH5UqVcp++8yZMwoNDVWHDh3sy7JkyaKePXtq//79CggI0Pbt21WrVi01bNhQkhQUFCRvb2/lzp1bkvTNN99o3759+vrrr1WpUiVJUp06ddShQweNHz9eS5YsSVHMN27c0KhRo1SzZk1J0mOPPabg4GBt3LhRpUqVStE4f/75p27evKlu3bqpQIECkqRChQpp7dq1un79urJnz55k3CZNmmjKlClas2aNmjdvLklauXKlsmXLpnr16un8+fM6dOiQunfvrrp160q6ddXltGnTklw1m1i2bNk0ceJEubu7q1atWlq2bJnOnDmjRYsWKUeOHKpbt65++eUX/fbbb5KkgwcPavHixerdu7def/11SdITTzyh/Pnzq1+/ftq0aZPq1q2rjz/+WOXLl9eECRPs50GS/faD3i+OOse3r2QtWLDgA021UbduXfs0ITVr1tTPP/+sDRs26O2339aVK1cUFhamNm3a2KcoqF27tnx8fPT+++/r1VdfVZkyZbR9+3b16NFD9evXl3Trcezj4yOr1ZrsuL/88otKlSqlbNmy2ZdFRkZKkooWLZri+Js0aaLx48drxYoV9nmEbTabVq5cqUaNGilr1qwJtvf29lapUqW0bds2tWnTJsXjAAAAuBoaugAAINMoX768hg0bJunW1br//vuvNm3apIkTJ+r69esKDQ2V9F8D8MKFCzp27JiOHDmidevWSZJiY2Ml3Wp8LVy4UFFRUQoODlbdunUTTFGwbds25cuXT+XLl0/wEffg4GCNGzdOly9fVq5cuVIU953NvtsfWb99pXBKxqlUqZK8vLzUqlUrPf/886pbt64CAwPl7++f7JhFixZV1apVtWrVKntDd9WqVWrQoIGyZMkiLy8vlS5dWoMGDdLWrVtVp04d1a5dW+++++598/H395e7+38vQ/Ply6fs2bMrR44c9mU+Pj46cOCAJGn79u2SlOAj/pLUsGFDvfvuuwoPD1dQUJD++usvvfXWWwm2ee655xI0dB/kfnHUOX5YiZvABQsW1MmTJyVJu3bt0o0bNxQSEpIg5pCQEEnSzz//rDJlyigoKEhTp07Vvn37VLduXdWpU+e+c0mfOHEiSeP29hzEyV2NfDd58uRRSEiIVq5caW/o/vzzzzpz5kyS6RZuK1KkiCIiIlI8BgAAgCuioQsAADKNbNmyqWLFigmW1a5dW9evX9fs2bP18ssv65FHHtHu3bs1bNgw7d69W1myZFHp0qVVpEgRSbJ/vH/gwIEqWLCgVqxYYW8SBwQEaPDgwfLz89OlS5d09uzZu14RLN2aSiGlDd07r1S83Ti7HUdKxildurS++OILzZw5U19//bU+++wz5cyZUy+++KJ69eqV7BeCNWvWTEOHDtXFixcVGRmpQ4cO2T+u7+bmprlz5yosLExr1qzRsmXL5OHhofr162vo0KHy8fFJNp+7Xa2a+GrMO12+fFnSrcbvndzd3ZU7d25duXJFly9flmEYypMnT4Jt8ufPn+D2g9wvjjzHDyPxObNYLAkeF5Ls8x0ndubMGUnSxIkT9cknn2j16tX6/vvvZbFYVKtWLQ0dOlTFihW7675Xr15NMvbt58epU6dUpkyZu+539uxZ5c6dO0Ezv1WrVurSpYv+/PNP+fv765tvvlG5cuUSfNla4pyvXLly13UAAACZBQ1dAACQ6T3++ONatGiRIiIi5OXlpc6dO8vX11fffvutSpUqJYvFoo0bN+qHH36w7+Pp6anXX39dr7/+uk6dOqX169dr+vTpevvtt7V69WrlyJFDjz32mMaPH3/XMVPz0fR7Sek4t6dDiImJ0c6dO/XVV1/pk08+ka+vr55//vm77vvss89qxIgRWrNmjY4dO6ZChQqpevXq9vUFChTQ0KFDNWTIEO3bt0/ff/+9Zs2apVy5ctmb3GnhdoP17NmzCc5bbGysLl68qNy5c8vHx0cWi0Xnzp1LsO/txuZtD3K/OPIcJ3b7y/lsNpt92oPEX3SWEjlz5pR0az7oxx57LMn6vHnzSrqV2zvvvKN33nlHhw8f1tq1azV9+nQNGzZMs2fPvuuxbzfR71SjRg15eHho48aN9ik4EuvWrZtu3Lih1atX25fVrl1bBQsW1MqVK1WyZEn99NNPSeY9vtO///5rn9YEAAAgs+JL0QAAQKa3a9cuWa1WFStWTIcPH9alS5f08ssvq0yZMvYrKzdt2iTp1kfKb968qQYNGmju3LmSpMKFC6t9+/Zq2LChfS7R6tWr6/Tp03rkkUdUsWJF+8+2bds0e/bse85RmhopGeezzz5TSEiIYmJi5OnpqZo1a2rEiBGSpNOnTyd77Bw5cig4OFhr167V999/r8aNG9vPx65du1SrVi39+eefcnNz0+OPP67Q0FCVLVvWfg7Syu0m8sqVKxMsX7VqlWw2m6pWrSovLy8FBAToxx9/tF+lKsk+Vcadx0rt/eLIc5z4yt3bVy/fuc/tuYRTo1KlSvLw8FBUVFSCmD08PDRhwgRFRETo5MmTqlu3rr7//ntJUsmSJdWlSxfVqlXrnvdh4cKFk+SUM2dOtWrVSl9//bX+/PPPJPt8++23+uuvv9S0adMEyy0Wi5o3b641a9Zo3bp1MgwjydQadzp9+rT9amAAAIDMiit0AQBApnH16lX9/vvv9tuxsbFau3atVq5cqTZt2ihPnjzy8PBQ9uzZ9cknn8jd3V3u7u764YcftHjxYkm3vqQsS5YsKl++vKZNmyYPDw/5+vrqyJEjWrZsmRo0aCBJatGihb744gu9+uqr6t69uwoVKqStW7dq1qxZeumll+Th4ZEmOaVknBo1amj8+PF644039NJLL8lqtWrhwoXy9PRUcHDwPY/frFkzvfHGG7LZbGrSpIl9uZ+fn7JkyaJ+/fqpZ8+eyps3r7Zu3aq///5bL7/8cprkdlvp0qXVvHlzTZs2TTdv3lRQUJD+/vtvTZs2TUFBQXryyScl3fpyu1deeUVvvvmm2rRpo6NHjyosLCzV5ysxR57jnDlzateuXfr1118VGBiounXr6oMPPtCgQYPUpUsXRUZGatq0aQm+gCwlcufOrc6dO2vy5Mm6evWqgoKCFBUVpcmTJ8vNzU3lypVTjhw5VLBgQY0cOVJXr15V8eLFtWfPHm3cuFHdunVL9thPPPGEVq9erStXriSY97hPnz7avXu3XnnlFbVv315BQUGKi4vT5s2b9fXXX6tOnTrq3LlzkuO1bNlSn3zyiT7++GM9/fTTyU5FcuXKFR08eFCdOnVK1bkAAABwNTR0AQBAprF37161adPGftvLy0vFixdXaGiovUmUI0cOTZ8+XePGjVOvXr2ULVs2Pf744/riiy/UpUsX7dixQyEhIRo+fLgmTZqkuXPn6uzZs3rkkUfUqlUr9erVS5Lk7e2tBQsWaMKECfrwww915coVFSlSRG+//bZee+21NMspJeOUK1fO3jDr06ePbDabKlSooLlz56pkyZL3PP6TTz6pXLlyqWDBggnmRvXy8tLcuXM1YcIEjRo1Sv/++68ee+wxDR8+XC1atEiz/G4bNWqUHn30US1ZskRz5sxR/vz51aFDB73xxhv2q1wDAwM1a9YsffTRR3rzzTdVtGhRjR49Wt27d0/V+UrMkee4e/fumj59urp06aLvvvtOJUqU0NixYxUWFqauXbuqVKlSGjFihP1q39To3bu38uXLpy+//FKzZ89Wrly5VLNmTfXp08feiJ02bZo++ugjTZ48WRcvXlShQoX05ptvJjv3rnTry+Dc3d21efPmBFNJ5MyZU/Pnz9cXX3yh7777TgsXLpRhGHr00Uf17rvvqnXr1gnmz72tWLFiCgoK0i+//HLPqTo2b94sDw8PPfXUU6k+FwAAAK7EzbjzM2kAAAAAcB8jRozQwYMH9fnnn6fbmB06dFC5cuU0cODAdBsTAAAgI2IOXQAAAACp0r17d/399993nS/XEf744w/t37//nlcOAwAAZBZcoQsAAAAg1b777jvNmzdPCxcudPhYbdu21UsvvaRGjRo5fCwAAICMjoYuAAAAAAAAAJgEUy4AAAAAAAAAgEnQ0AUAAAAAAAAAk6ChCwAAAAAAAAAmQUMXAAAAAAAAAEyChi4AAAAAAAAAmAQNXQAAAAAAAAAwCRq6AAAAAAAAAGASNHQBAAAAAAAAwCRo6AIAAAAAAACASdDQBQAAAAAAAACToKELAAAAAAAAACZBQxcAAAAAAAAATIKGLgAAAAAAAACYBA1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJGjoAgAAAAAAAIBJ0NAFAAAAAAAAAJOgoQsAAAAAAAAAJkFDF8AD6dChg3x9fRP8lCtXTlWrVlXr1q21atUqp8QVEREhX19fLV26VJK0dOlS+fr6KiIiItl97pbLnT87duxI8fgDBgxQSEiI/XZISIgGDBjw4AkBAFzGgAED7llvvvnmmwTbX716VSEhIfaaBgBASvTr10++vr6aOXOms0MB4CDuzg4AgHn5+flpyJAh9ts2m02RkZH67LPP1KdPH+XIkUN16tRxYoQplziXO5UuXTrFx+nRo4defvnltAoLAOBi8uXLp2nTpt11XfHixe2/X7p0Sa+//rpOnjyZXqEBAFzA1atX9eOPP6ps2bL6+uuv1aVLF7m5uTk7LABpjIYugAeWPXt2Va5cOcnyunXrqmbNmlqyZIlpGrrJ5ZJad74ZBwAgMU9Pz/vWm59++kmjRo3S9evX0ycoAIDLWLVqlWw2m95//329/PLL2rJli5588klnhwUgjTHlAoA05+npKQ8PjyTLFy1apIYNG6pChQp66qmnNHXqVMXFxSXY5ueff1b79u0VEBCg2rVra/Dgwbp8+bJ9/a+//qpOnTqpWrVqqlChgkJCQjR16lTFx8c7PK+bN29qwoQJeuaZZ1ShQgVVqVJFr776qv7++2/7NomnXAAAIDX+/fdf9ezZU9WrV9fs2bOdHQ4AwGSWLFmioKAgBQUFqUSJElq4cGGSbVatWqUWLVqoUqVKeuqpp/Thhx8qJibGvn7Pnj3q3Lmzqlatqho1aig0NFSnT5+WJIWHh8vX11fh4eEJjtmhQwd16NDBfjskJESjR4/WK6+8oipVqmjw4MGSpH379unNN99UjRo1VL58eT355JMaOXKkbt68ad83NjZWH3/8serXry9/f381bNhQS5YskSQtWLBAvr6+OnLkSJKcypUrd8+p9gBXQkMXwAMzDENxcXH2n+joaB07dkzvv/++rl27pqZNm9q3nTFjhgYNGqSaNWvqk08+Ufv27TVr1ix7YZekjRs3qnPnzvLx8dHEiRP1zjvvaN26dXrrrbck3Sr+HTt2tK8PCwtTlSpVNG3atIeeszdxLrd/DMOwb9OvXz8tXrxYXbt21dy5czVgwAAdOHBAoaGhCbYDAOBe7lVvsmTJolWrVmns2LHKnTu3kyMFAJjJoUOH9Mcff6h58+aSpBYtWmj9+vWKioqyb7Nw4UL16dNHjz/+uKZNm6Zu3brpyy+/1NChQyXdes/Vrl073bhxQ2PGjNHw4cO1d+9evfbaa4qNjU1VPLebr1OnTlXTpk115swZtW/f3n7sWbNm6bnnntP8+fP12Wef2ffr37+/Zs6cqVatWmnGjBmqW7eu3nvvPS1fvlyNGzeWl5dXknnnly1bpurVq6to0aIPdvIAk2HKBQAP7Ndff1X58uUTLHNzc1PZsmU1efJk+5WqV65cUVhYmNq0aaP3339fklS7dm35+Pjo/fff16uvvqoyZcpoypQpKleunD7++GP78bJkyaKPPvpIUVFR2rdvn2rVqqUPP/xQFsut/0c98cQT2rBhg3799Vc1btw4TXORpHHjxqlp06aKiYnRtWvXNGjQID3//POSpOrVq+vatWsaM2aMzp49q/z58z/w+ACAzOHkyZN3rTe9evVSjx495OnpqZIlSzohMgCA2S1evFg5c+ZU/fr1JUnNmjXTpEmTtGjRIr355puKj4/X1KlT9fTTT2vUqFH2/aKjo7Vs2TLFxMRo+vTpypUrl+bOnSsvLy9JUsGCBdW7d2/t378/VfHkz59fAwYMsL9327Jlix5//HFNnjxZ2bNnlyTVqlVL27Zt06+//qru3bvrn3/+0apVqzRw4ED7d5PUrFlTp06dUnh4uJo1a6ann35aK1asUK9eveTm5qYzZ85o69atGj169EOfQ8AsaOgCeGDly5fXsGHDJElRUVGaPHmyYmNjNXHiRJUqVcq+3a5du3Tjxg2FhIQkmGLhdsP3559/VrFixfTXX3+pZ8+eCcZo0KCBGjRoIOnWC5JmzZopOjpax48f17Fjx/TXX3/JZrOl+r/F98rlTsWKFZN0axqJOXPmSJLOnDmjY8eO6fDhw1q/fr0kPfT4AIDMIV++fAoLC0uyvECBAk6IBgDgKuLi4rRixQrVr19f0dHRio6OVpYsWRQUFKRFixbp9ddf19GjR3Xu3Dl7w/e2jh07qmPHjpKknTt3qm7duvZmriT5+/tr3bp1kpRkqoV7KVWqlL2ZK926qKd27dqKjY3VkSNHdPToUe3fv18XLlyQj4+PJGnHjh2SpKeffjrBsSZNmmT/vVWrVvr222+1Y8cOVatWTd98842yZMlif98IZAY0dAE8sGzZsqlixYqSpIoVKyogIEBNmzbVa6+9pmXLlilPnjySbn1TtyR17dr1rsc5c+aMLl++LMMw9MgjjyQ73s2bNzVixAh98803iouLU9GiRRUQECB3d/eHnvLgzlySs3nzZo0ePVqHDx9WtmzZ5Ovrq2zZskkSUy4AAFLE09PzvvUGAIDU2rBhg86dO6elS5dq6dKlSdavX7/ePpXPvd5zXbp06Z7rUyNv3rwJbsfHx+ujjz7SggULdP36dRUqVEj+/v4Jmse33zveK4YaNWqoaNGiWr58uapVq6bly5frueeeU9asWdMkbsAMaOgCSDOPPPKIBg8erJ49e2rUqFGaMGGCJClnzpySpPHjx+uxxx5Lsl/evHmVPXt2ubm56cKFCwnWxcTEaNu2bfL399dHH32kH374QZMmTVKtWrXk7e0t6dZHcBzt+PHjeuONN1SvXj3NmDFDxYsXl3RrXqjNmzc7fHwAAAAASM7ixYtVpEgRffDBB0nWvfXWW1q4cKH69+8vSUnec126dEl//fWXKleurBw5ciRZL936vpNy5crJzc1NkpJ8KfW1a9fsF7skZ+bMmfrss880dOhQNWjQQDly5JB064rb226/d7xw4YIKFixoX3748GFduHBBgYGBcnNzU/PmzTVv3jy1b99eBw8e1PDhw+85NuBq+FI0AGnqmWee0ZNPPqlvv/3W/nGcSpUqycPDQ1FRUapYsaL9x8PDQxMmTFBERISyZcumxx9/XGvXrk1wvC1btqhr166KjIzUzp07FRQUpPr169ubuXv27NGFCxeSvKBIa3v27FF0dLS6detmb+ZKsjdzuUIXAAAAgDOcO3dOmzdvVsOGDRUUFJTk5/nnn9fPP/8sLy8v5c6dO8l7rpUrV6pLly6Kjo5WYGCgNm/erJiYGPv6/fv3q2vXrtq9e7d97tvTp0/b11++fFmHDh26b5w7d+5U6dKl1apVK3szNyoqSgcOHLC/n6tataok6aeffkqw78SJEzVixAj77ZYtW+rKlSv64IMP9Nhjj9n3AzILrtAFkObee+89NWnSRCNHjtSyZcuUO3dude7cWZMnT9bVq1cVFBRkn3PXzc1N5cqVk3TrP8evv/66evfurRYtWujChQuaMGGCgoOD9fjjj8vf31+rV6/W//73P5UqVUr79u1TWFiY3NzcdOPGDYfmVL58ebm7u+vDDz/Ua6+9ppiYGC1dulQbNmyQJF2/ft2h4wMAAADA3SxbtkxxcXFq2LDhXdc3b95cX375pRYtWqSePXtq+PDhGjp0qJ5++mkdPXpUkyZNUrt27ZQnTx716NFDbdq0UZcuXfTKK68oJiZGkydPVvny5VWnTh1ZrVYVKlRI06ZNU44cOWSxWDRz5swUTXfg7++v6dOna+bMmapcubKOHTumGTNmKCYmxv5+rly5cnr22Wc1fvx43bx5U+XLl9eWLVu0Zs2aBPPoFipUSLVq1dKWLVsUGhqaJucRMBMaugDSXMmSJdWhQwfNnTtXX3zxhTp27KjevXsrX758+vLLLzV79mzlypVLNWvWVJ8+fez/nQ0ODtaMGTM0depUvfHGG8qdO7eee+459erVS5I0YMAAxcbGatKkSYqJiVHRokX1+uuv6+DBg1q3bp1sNpvDcnr00Uc1YcIETZs2Ta+//rpy5cqlypUra/78+erQoYN27NghX19fh40PAAAAAHezbNkylSlTxn6hTGL+/v4qWbKklixZog0bNsjb21tz5szR4sWLVaBAAb322mv27zvx8/PT/PnzNWHCBIWGhipbtmyqW7eu+vbtK09PT0nSlClTNHr0aPXp00d58+bVK6+8osOHD+vIkSP3jLNbt266ePGi5s2bp48//liFChVS06ZN5ebmphkzZujy5cvKlSuXPvzwQ02bNk3z58/XxYsXVaJECU2aNEnPPvtsguMFBwdr69atatas2cOfRMBk3Aw+JwwAAAAAAAAT6dKli6xWqz755BNnhwKkO67QBQAAAAAAgCl8/PHHOnLkiDZt2qQvvvjC2eEATkFDFwAAAAAAAKawbt06HTt2TO+8846qVavm7HAAp2DKBQAAAAAAAAAwCYuzAwAAAAAAAAAApAwNXQAAAAAAAAAwCRq6AAAAAAAAAGASfClaBhcfH6+4uDhZLBa5ubk5OxwAgIswDEPx8fFyd3eXxeKY/+9SwwAAjuLoOkYNAwA4SlrUMBq6GVxcXJx2797t7DAAAC6qYsWK8vT0dMixqWEAAEdzVB2jhgEAHO1hahgN3Qzudqfez8/PYW+4Hclms2n37t2qWLGirFars8NJNeJ3LrPHL5k/B+J3LkfGf/vYjro6VzJ/DUvM7I+nxFwpH1fKRSKfjI58MgZH1zFXq2HJMev9n1rk6VrI07VkxjwlPXQNo6Gbwd3+eI/VajX1A5v4nYv4nc/sORC/czkyfkd+jNRValhi5JNxuVIuEvlkdOSTMTiqjrlqDUsOeboW8nQt5Ola7szxYWoYX4oGAAAAAAAAACZBQxcAAAAAAAAATIKGLgAAAAAAAACYBA1dOFzWrFmdHcJDIX7nMnv8kvlzIH7nMnv8rsbV7g9XyseVcpHIJ6NztXyQuWWWxzN5uhbyRGbHl6KZhFknhrZarfLz83N2GA+M+J3L7PFL5s+B+J3rbvHb4uNlddA3ejuKWWtYYmZ/PCXmSvm4Ui4S+WR0Kc3HjH+vkZSr1LDkuNrzMznk6VrIM+Oh5qU/GromMWLRVv0TednZYQAAnKhE/lwa+eKTzg4j1ahhADIbs/69RlLUMAC4N2qec9DQNYljZ//VvpMXnB0GAACpRg0DAJgVNQwAkBFxPTQAAAAAAAAAmAQNXQAAAAAAAAAwCRq6AAAAAAAAAGASNHQBAAAAAAAAwCRo6AIAAAAAAACASdDQBQAAAAAAAACToKELAAAAAAAAACZBQxcAAAAAAAAATIKGLgAAAAAAAACYBA1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJGjoAgAAAAAAAIBJ0NAFAAAAAAAAAJOgoQsAAAAAAAAAJkFDFwAAAAAAAABMgoYuAAAAAAAAAJgEDV0AAAAAAAAAMAmXb+guXbpUISEh6TbeJ598os6dOye7vkOHDpo6dWq6xQMAAAAAAADAdbg7OwBX0717d2eHAAAAAAAAAMBFmeYK3VWrVqlChQrat2+fJGnv3r3y9/fXpk2btHfvXrVr104BAQFq2rSpwsLCElyVGxcXp7Fjx6pWrVqqX7++Zs+eLcMwUjTuxYsXFRoaqqpVq6pevXqaP3++/Pz8FBERoYiICPn6+mrMmDGqVq2ahg0bpqlTp6pDhw72/RctWqR69eopICBA/fv3140bN9L2xAAAAAAAAADINEzT0G3YsKEaN26sfv366fLlywoNDVXHjh1VpUoVde7cWTVq1FB4eLjGjRunr7/+OsG+UVFRslgs2rBhgyZNmqRZs2bpm2++SdG4ffv21ZUrV7R27VotWrRI69evl81mS7DNtWvX9PPPPys0NDTB8m3btmn48OEaOXKkfv31V1WqVEm7d+9+uBMBAAAAAAAAINMyTUNXkgYNGqSYmBg1b95c+fLlU69evbRu3TpZrVb17NlTnp6e8vX1TTKHbe7cudWnTx95enqqQoUKatOmjVasWHHf8aKiorRlyxa999578vHxUZ48efTee+8l2a5Zs2by9PRUzpw5EyxfsWKFnnnmGdWsWVPu7u568cUX5efn93AnAQAAAAAAAECmZaqGrre3t1q2bKmTJ0+qefPmslqtioyMVOHChWWx/JdKsWLFEuxXqFAhWa3WBLejoqLuO97p06clSUWLFk322JKUP3/+u+4fFRWlwoULJ1h2t/0BAAAAAAAAICVM1dA9fvy4wsLC1Lp1a40bN87ezD116lSCOXFPnTqVYL+zZ88mWH/ixAkVKVLkvuPdbsaePHnSvuzO329zc3O76/4FCxbUiRMnEiyLjIy877gAAAAAAAAAcDemaejGxsaqT58+atiwoUaOHKlq1arpnXfeUUhIiAzD0CeffKKYmBgdPnxYc+bMSbDv2bNnFRYWppiYGO3atUuLFi1S27Zt7ztm/vz5FRwcrA8//FCXL1/W5cuXNW7cuBTH3LJlS/30009av3694uLitGzZMv3xxx+pzh0AAAAAAAAAJBM1dCdPnqyLFy9qwIABkqThw4fr4MGD+vzzzzV9+nStXbtW1atXV58+ffTEE0/Iw8PDvq+vr68iIiIUFBSk/v37q1+/fgoJCUnRuKNGjZKbm5ueeuopNW/e3D4H7p3HT07VqlU1btw4jRkzRoGBgfrhhx/0xBNPPED2AAAAAAAAACC5OzuAlOrbt6/69u1rv50nTx5t27ZNFy9e1OHDh7V48WL7uvnz52vfvn2SpBYtWqhFixaSpNGjR6d63H379mnChAnKkiWLJGn//v0KCwuTj4+PvLy8tH///gTb9+zZM8Ht559/Xs8//3yqxwUAAAAAAACAxExzhW5ybDabXnnlFW3cuFGSFBERoS+//FLBwcFpcvyxY8cqLCxMcXFxunr1qsLCwlSrVi15eXmlyfEBAAAAAAAAIKVMc4VucvLmzatJkyZp/Pjx6t27t3LmzKnmzZurU6dO9933jTfe0NatW5NdP2zYME2YMEEjR45UjRo1ZLFY9OSTT6ZqHl0AAAAAAAAASCumb+hKUv369VW/fv1U7/fxxx+naLvPP/881ccGAAAAAAAAgLRm+ikXAAAAAAAAACCzoKELAAAAAAAAACZBQxcAAAAAAAAATIKGLgAAAAAAAACYBA1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJGjoAgAAAAAAAIBJ0NAFAAAAAAAAAJOgoQsAAAAAAAAAJkFDFwAAAAAAAABMgoYuAAAAAAAAAJgEDV0AAAAAAAAAMAkaugAAAAAAAABgEjR0AQAAAAAAAMAk3J0dAFLm0Xw5FWMznB0GAMCJSuTP5ewQHgg1DEBmY9a/10iKGgYA90bNcw4auiYxqHUtWa1WZ4cBAHAyW3y8rBZzfcCGGgYgMzLj32skRQ0DgPuj5qU/zrZJ2Gw2Z4fwQGw2m/bu3Uv8TkL8zmf2HIjfue4WvxlfKJn1/Cdm9sdTYq6UjyvlIpFPRpfSfMz49xpJucrjNjmu9vxMDnm6FvLMeKh56Y8zDoe7ceOGs0N4KMTvXGaPXzJ/DsTvXGaP39W42v3hSvm4Ui4S+WR0rpYPMrfM8ngmT9dCnsjsaOgCAAAAAAAAgEnQ0AUAAAAAAAAAk6ChCwAAAAAAAAAmQUMXAAAAAAAAAEyChi4AAAAAAAAAmAQNXQAAAAAAAAAwCRq6AAAAAAAAAGASNHQBAAAAAAAAwCRo6AIAAAAAAACASdDQhcNlzZrV2SE8FOJ3LrPHL5k/B7PHD6QlV3s+uFI+rpSLRD4Znavlg8wtszyeydO1kCcyO3dnB4CUsVqtzg7hgVitVvn5+Tk7jAdG/M5l9vgl8+eQnvEb8Ta5Wcz5tw73ZtYalpjZn8+JuVI+rpSLRD4ZXUbNhzrqGK5Sw5KTUR/PaY08XQt5ugbq1sOhoWsS51cMke3sAWeHAQAO4ZG3pPK2GOPsMOAg1DAAcCzqqONQwwAg7VG3Hh4NXZOIPX9Utsi/nR0GAACpRg0DAJgVNQwAkBExhy4AAAAAAAAAmAQNXQAAAAAAAAAwCRq6AAAAAAAAAGASNHQBAAAAAAAAwCRo6AIAAAAAAACASdDQBQAAAAAAAACToKELAAAAAAAAACZBQxcAAAAAAAAATIKGLgAAAAAAAACYBA1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJGjoAgAAAAAAAIBJ0NAFAAAAAAAAAJOgoQsAAAAAAAAAJkFDFwAAAAAAAABMgoYuAAAAAAAAAJgEDV0AAAAAAAAAMAmXaOhGRETI19dXERERzg4FAAAAAAAAABzGJRq6AAAAAAAAAJAZuDs7gLR28uRJffjhhwoPD5fFYlGNGjXUv39/5c+fX5K0detWjRs3TsePH1fZsmVVtWpV/fnnn5o/f/59j92hQwcVKVJE4eHhMgxD3377rS5cuKDRo0dr165d8vb2VpMmTfTGG2/I09NTkrRq1SpNmTJF58+fV6VKlVS4cGHFxsZqzJgxDj0PAAAAAAAAAFyPS12hGxcXp9dee01Wq1U//vijVq9eLUnq3r274uLiFBERoe7du6tdu3bavn27+vbtq6+++ipVY2zdulULFy7UihUrZLFY1LFjR5UpU0abNm3Sl19+qa1bt2rq1KmSpF27dql///7q37+/fvnlF7Vt21ZLly5N87wBAAAAAAAAZA4u1dDdsWOHTpw4oWHDhilHjhzKmTOnhg0bpn379mnPnj1auXKlHn/8cbVp00bu7u4KDAzUCy+8kKox6tSpowIFCihnzpzasGGDYmJi1KdPH3l5ealQoULq1auXFixYIElasmSJnnnmGYWEhMjd3V1PP/206tev74jUAQAAAAAAAGQCLjXlwvnz55U7d25lz57dvix79uzy8fHRyZMndfr0aRUpUiTBPsWKFdPu3btTPMbtqRukW9M7XLhwQdWqVbMvMwxDsbGxOn/+vE6fPi0/P78k4507dy61qQEAAAAAAACAazV0q1evrsmTJ+vq1av2pu6VK1d08eJF5cuXT0WKFNH69esT7HPq1KlUjeHm5mb/vWDBgipevLi+//57+7KrV6/q/PnzypMnj4oUKZLk+KdOnbLPrwsAAAAAAAAAqeFSUy7kyZNHpUuX1pAhQ3TlyhVduXJFQ4cOVfHixVWlShU1bdpUf//9t5YvXy6bzaY//vhDX3/99QOPFxwcrGvXrmn27NmKiYnRv//+q/79+ys0NFRubm5q3bq11qxZo82bN8tms2njxo368ccf0zBjAAAAAAAAAJmJSzV0rVarZsyYobi4ODVo0EDBwcGKjY3Vp59+Knd3dxUsWFBTpkzRrFmzFBgYqLFjx6p27dry8PB4oPGyZ8+uzz77TOHh4apTp47q168vi8WisLAwSVLFihU1bNgwDR06VNWqVdOCBQtUs2bNBx4PAAAAAAAAQObmElMuFC1aVPv377ffnjx58l23O336tPLly6dVq1bZl40ZMybF48yfPz/JslKlSmnWrFl33f7IkSPy9/fX2rVr7ct69uypPHnypHhMAAAAAAAAALjNpa7QvZ+LFy/qxRdf1J49eyRJ+/bt04oVKxQcHOyQ8Q4ePKhXXnlFx48flySFh4dr8+bNqlu3rkPGAwAAAAAAAODaXOIK3ZTy8/PTwIED1adPH509e1Z58+ZV165d1ahRI40aNUqLFy9Odt9u3bqpe/fuqRrv6aef1sGDB/Xyyy/r8uXLKlKkiEaMGKEqVao8bCoAAAAAAAAAMqFM1dCVpNatW6t169ZJlg8cOFADBw5M8/Fef/11vf7662l+XAAAAAAAAACZT6aacgEAAAAAAAAAzIyGLgAAAAAAAACYBA1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJGjoAgAAAAAAAIBJ0NAFAAAAAAAAAJOgoQsAAAAAAAAAJkFDFwAAAAAAAABMgoYuAAAAAAAAAJgEDV0AAAAAAAAAMAkaugAAAAAAAABgEjR0AQAAAAAAAMAkaOgCAAAAAAAAgEnQ0AUAAAAAAAAAk6ChCwAAAAAAAAAm4e7sAJAyHo88Jkt8jLPDAACH8Mhb0tkhwIGoYQDgWNRRx6GGAUDao249PBq6JvFIk2GyWq3ODgMAHMaIt8nNwt85V0QNAwDHo446BjUMAByDuvVwmHLBJGw2m7NDeCA2m0179+4lfichfuczew7pGT/F3HWZ9fGfmNmfz4m5Uj6ulItEPhldRs2HOuoYGe1+TmsZ9fGc1sjTtZCna6BuPRwaunC4GzduODuEh0L8zmX2+CXz52D2+IG05GrPB1fKx5Vykcgno3O1fJC5ZZbHM3m6FvJEZkdDFwAAAAAAAABMgoYuAAAAAAAAAJgEDV0AAAAAAAAAMAkaugAAAAAAAABgEjR0AQAAAAAAAMAkaOgCAAAAAAAAgEnQ0AUAAAAAAAAAk6ChCwAAAAAAAAAmQUMXAAAAAAAAAEyChi4cLmvWrM4O4aEQv3OZPX7J/DmYPX4gLbna88GV8nGlXCTyyehcLR9kbpnl8UyeroU8XUtmyTMtuTs7AKSM1Wp1dggPxGq1ys/Pz9lhPDDidy6zxy+ZP4eUxm/E2+RmMeffKTieWWtYYmZ/PifmSvm4Ui4S+WR0rpaPxU3y8PBwdhgZlqvUsOS42uM5OeTpWsjTtfCe88HQ0DWJ8yuGyHb2gLPDAIAkPPKWVN4WY5wdBjIwahgAZEy3a7i7O28Lk0MNAwDn4z1nUlRuk4g9f1S2yL+dHQYAAKlGDQMAmBU1DACQETGHLgAAAAAAAACYBA1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJGjoAgAAAAAAAIBJ0NAFAAAAAAAAAJOgoQsAAAAAAAAAJkFDFwAAAAAAAABMgoYuAAAAAAAAAJgEDV0AAAAAAAAAMAkaugAAAAAAAABgEjR0AQAAAAAAAMAkaOgCAAAAAAAAgEnQ0AUAAAAAAAAAk6ChCwAAAAAAAAAmQUMXAAAAAAAAAEyChi4AAAAAAAAAmAQNXQdaunSpQkJCnB0GAAAAAAAAABdBQxcAAAAAAAAATIKGbgqsWrVKFSpU0L59+yRJe/fulb+/vzZt2qS9e/eqXbt2CggIUNOmTRUWFpbgqty4uDiNHTtWtWrVUv369TV79mwZhuGsVAAAAAAAAACYmLuzAzCDhg0basuWLerXr5/mz5+v0NBQdezYUVWqVNEzzzyjNm3a6PPPP9eRI0fUvXt3ubm52feNioqSxWLRhg0bdODAAXXq1El58+ZVs2bNnJcQAAAAAAAAAFPiCt0UGjRokGJiYtS8eXPly5dPvXr10rp162S1WtWzZ095enrK19dXnTt3TrBf7ty51adPH3l6eqpChQpq06aNVqxY4aQsAAAAAAAAAJgZDd0U8vb2VsuWLXXy5Ek1b95cVqtVkZGRKly4sCyW/05jsWLFEuxXqFAhWa3WBLejoqLSLW4AAAAAAAAAroOGbgodP35cYWFhat26tcaNG2dv5p46dSrBnLinTp1KsN/Zs2cTrD9x4oSKFCmSbnEDAAAAAAAAcB00dFMgNjZWffr0UcOGDTVy5EhVq1ZN77zzjkJCQmQYhj755BPFxMTo8OHDmjNnToJ9z549q7CwMMXExGjXrl1atGiR2rZt66RMAAAAAAAAAJgZDd0UmDx5si5evKgBAwZIkoYPH66DBw/q888/1/Tp07V27VpVr15dffr00RNPPCEPDw/7vr6+voqIiFBQUJD69++vfv36KSQkxFmpAAAAAAAAADAxd2cHYAZ9+/ZV37597bfz5Mmjbdu26eLFizp8+LAWL15sXzd//nzt27dPktSiRQu1aNFCkjR69Oj0DRoAAAAAAACAy+EK3Ydgs9n0yiuvaOPGjZKkiIgIffnllwoODnZyZAAAAAAAAABcEVfoPoS8efNq0qRJGj9+vHr37q2cOXOqefPm6tSpk7NDAwAAAAAAAOCCaOg+pPr166t+/frODgMAAAAAAABAJsCUCwAAAAAAAABgEjR0AQAAAAAAAMAkaOgCAAAAAAAAgEnQ0AUAAAAAAAAAk6ChCwAAAAAAAAAmQUMXAAAAAAAAAEyChi4AAAAAAAAAmAQNXQAAAAAAAAAwCRq6AAAAAAAAAGASNHQBAAAAAAAAwCRo6AIAAAAAAACASdDQBQAAAAAAAACToKELAAAAAAAAACZBQxcAAAAAAAAATIKGLgAAAAAAAACYBA1dAAAAAAAAADAJd2cHgJTxeOQxWeJjnB0GACThkbeks0NABkcNA4CMiRp+f9QwAHA+6lVSNHRN4pEmw2S1Wp0dBgDclRFvk5uFv1G4O2oYAGRcRrxNcXFxzg4jw6KGAUDGwHvOhJhywSRsNpuzQ3ggNptNe/fuJX4nIX7nM3sOKY2fwop7MevjPzGzP58Tc6V8XCkXiXwyOlfLJ96QYmNjnR1GhuUq93NyXO3xnBzydC3k6Vp4z/lgaOjC4W7cuOHsEB4K8TuX2eOXzJ+D2eMH0pKrPR9cKR9XykUin4zO1fJB5pZZHs/k6VrI07VkljzTEg1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJGjoAgAAAAAAAIBJ0NAFAAAAAAAAAJOgoQsAAAAAAAAAJkFDFwAAAAAAAABMgoYuAAAAAAAAAJgEDV0AAAAAAAAAMAkaunC4rFmzOjuEh0L8zmX2+CXz52D2+IG05GrPB1fKx5VykcgnoyMfuJLMcv+Tp2shT9eSWfJMS+7ODgApY7VanR3CA7FarfLz83N2GA+M+J3L7PFL5s8hJfHb4uNltfD/QSTPrDUsMbM/nxNzpXxcKReJfDI68nlwZnzN4Co1LDmu9nhODnm6FvJ0LWbKMyPVMRq6JjFi0Vb9E3nZ2WEAQAIl8ufSyBefdHYYyOCoYQAAs75moIYBAKSMV8do6JrEsbP/at/JC84OAwCAVKOGAQDMihoGAMiIMsZ1wgAAAAAAAACA+6KhCwAAAAAAAAAmQUMXAAAAAAAAAEyChi4AAAAAAAAAmAQNXQAAAAAAAAAwCRq6AAAAAAAAAGASNHQBAAAAAAAAwCRo6AIAAAAAAACASdDQBQAAAAAAAACToKELAAAAAAAAACZBQxcAAAAAAAAATIKGLgAAAAAAAACYBA1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJGjoAgAAAAAAAIBJ0NAFAAAAAAAAAJPI0A3do0ePOjsEAAAAAAAAAMgwMmxDd8GCBRo0aJCzw3goERER8vX1VUREhLNDAQAAAAAAAOACMmxD98KFC84OAQAAAAAAAAAyFIc3dPfv368uXbqoevXqqlOnjoYOHaorV65o6dKleuGFFzR48GBVqVJFtWvX1vTp02UYhpYtW6YZM2Zox44dCgwMlCSFhIRo6dKl9uOGh4fL19dX0n9Xwi5atEghISGqWrWqXn31VUVGRkqSDMPQzJkz1bhxYwUGBqpatWp6++23dfPmzfvGf+zYMQUEBGjBggWSpKtXr+rpp5/WhAkTJEkXL15UaGioqlatqnr16mn+/Pny8/NLcFXu8uXLVb9+fdWqVUvvv/++rl69mjYnFwAAAAAAAECm4tCG7sWLF/Xyyy+rdOnS2rRpk5YsWaIjR46oX79+kqQ//vhDWbNm1bZt2xQWFqbPP/9cixcvVvPmzdWtWzcFBgZqx44dKR5vw4YNWr58uX744QedO3dO06dPlyStXr1a8+bN09SpU7Vjxw4tXLhQW7Zs0cqVK+97zEcffVRDhgzR+PHjdeLECQ0ZMkT58+dX7969JUl9+/bVlStXtHbtWi1atEjr16+XzWZLcIwdO3bo66+/1ooVK3TgwAGNHj06xTkBAAAAAAAAwG0ObeiuXbtWHh4e6tu3r7JkyaJ8+fJp0KBBWrdunc6dOycfHx/17dtXXl5eqlixotq0aaMVK1Y88HhdunRRzpw5lTdvXoWEhNi/VK1OnTpavHixHnvsMV24cEEXL16Uj4+PoqKiUnTcZs2aqX79+nrllVe0detWffTRR7JarYqKitKWLVv03nvvycfHR3ny5NF7772XZP8BAwYoT548yps3r9566y2tXLlS8fHxD5wnAAAAAAAAgMzJoQ3d8+fPq3DhwrJarfZlRYsWtf9epEgReXh42G8XKlRIZ86ceeDx8ubNa//d3d1dhmFIujXlwsSJE1W9enW9+OKLWrBggWJjY+3rU6JDhw46efKk6tSpowIFCkiSTp8+nSSnYsWKJdn3zvWFChVSTEyMLl26lKrcAAAAAAAAAMChDd0iRYro1KlTCaYgOH78uCQpJiZGZ86cSdBUjYiIUOHChe8eqMWi2NhY++2LFy+mOI7x48fr1KlTWrdunb7//ntNnDhR2bJlS/H+MTExGjx4sBo1aqQffvhBGzdulCR7rCdPnrRve+fvt915JXBERIS8vb2VJ0+eFI8PAAAAAAAAAJKDG7p169aVdKuhevPmTZ09e1ajRo1SjRo1VLhwYZ09e1YzZ85UbGys/vzzTy1atEitW7eWJHl5eenq1av2hm+pUqW0du1a+3HmzZuX4jiuXr0qLy8vWa1WRUdHa+7cuTpw4ECCBvG9jB8/XjabTR988IH69OmjAQMG6OzZs8qfP7+Cg4P14Ycf6vLly7p8+bLGjRuXZP/b6yMjIzV58mS1adMmxbEDAAAAAAAAwG0ObejmyJFDn376qQ4cOKC6deuqUaNGKlKkiCZPnixJypcvnyIiIlS7dm317t1bvXr10vPPPy9JCg4O1qVLl1S1alX9+++/6tu3r65du6YnnnhCL7/8spo0aZLiOHr37q2bN2+qVq1aCgkJ0e+//66mTZvqwIED991306ZN+vLLLzV27Fh5enqqQ4cOKlOmjAYMGCDDMDRq1Ci5ubnpqaeeUvPmzeXn5ydJCaaSCAgI0LPPPquWLVuqWrVqCg0NTc1pBAAAAAAAAABJkrujByhTpozmzJlz13Wenp4aMWKERowYcdf91q9fb7+dM2dOLViwIME2bdu2lXRrjtr9+/cnWNezZ0/778WKFdMXX3zxQPHXqVNHe/bssd92c3NLcHXwvn37NGHCBGXJkkWStH//foWFhcnHx0deXl72uLp16/ZA4wMAAAAAAADAbQ69QjczGDt2rMLCwhQXF6erV68qLCxMtWrVkpeXl7NDAwAAAAAAAOBiHH6Fbkb3xhtvaOvWrcmuHzZs2D2nd5gwYYJGjhypGjVqyGKx6Mknn7zrPLoAAAAAAAAA8LCc1tBt0aKFWrRo4azh7T7++OOH2r9MmTL6/PPP0ygaAAAAAAAAAEgeUy4AAAAAAAAAgEnQ0AUAAAAAAAAAk6ChCwAAAAAAAAAmQUMXAAAAAAAAAEyChi4AAAAAAAAAmAQNXQAAAAAAAAAwCRq6AAAAAAAAAGASNHQBAAAAAAAAwCRo6AIAAAAAAACASdDQBQAAAAAAAACToKELAAAAAAAAACZBQxcAAAAAAAAATIKGLgAAAAAAAACYBA1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJNydHQBS5tF8ORVjM5wdBgAkUCJ/LmeHABOghgEAzPqagRoGAJAyXh2joWsSg1rXktVqdXYYAJCELT5eVgsf+EDyqGEAAMmcrxmoYQCA2zJSHcsYUeC+bDabs0N4IDabTXv37iV+JyF+5zN7DimJP6MUNGRcZn38J2b253NirpSPK+UikU9GRz4PzoyvGVzlfk6Oqz2ek0OeroU8XYuZ8sxIdSzjRAKXdePGDWeH8FCI37nMHr9k/hzMHj+Qllzt+eBK+bhSLhL5ZHTkA1eSWe5/8nQt5OlaMkueaYmGLgAAAAAAAACYBA1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJGjoAgAAAAAAAIBJ0NAFAAAAAAAAAJOgoQsAAAAAAAAAJkFDFwAAAAAAAABMgoYuHC5r1qzODuGhEL9zmT1+yfw5eHh4ODsEIMMw+/M5MVfKx5Vykcgno3O1fJC5ZZbHM3m6FvJEZufu7ACQMlar1dkhPBCr1So/Pz9nh/HAiN+5zB6/ZP4crFarKpT3k+HsQGBqZq1hiZn9+ZyYK+XjSrlI5JPRZfR8jHib3Cyu8Xc3I3CVGpacjP54Tivk6VrI07yoUWmHhq5JnF8xRLazB5wdBoBMxiNvSeVtMUY2m83ZocDEqGEAkD5u122kHWoYAKQNalTaoqFrErHnj8oW+bezwwAAINWoYQAAs6KGAQAyIubQBQAAAAAAAACToKELAAAAAAAAACZBQxcAAAAAAAAATIKGLgAAAAAAAACYBA1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJGjoAgAAAAAAAIBJ0NAFAAAAAAAAAJOgoQsAAAAAAAAAJkFDFwAAAAAAAABMgoYuAAAAAAAAAJgEDV0AAAAAAAAAMAkaugAAAAAAAABgEjR0AQAAAAAAAMAkaOgCAAAAAAAAgEnQ0AUAAAAAAAAAk6ChCwAAAAAAAAAmQUP3/0VERMjX11cRERH33C48PFy+vr7pFBUAAAAAAAAA/IeGLgAAAAAAAACYhLuzA8iIIiIiNGTIEO3atUv58+dX27Zt9cEHH2j//v32bWbOnKkFCxbIMAw1btxYvXr1kqenp6ZOnaqDBw8qS5YsWrNmjbJnz653331Xhw8f1oIFCxQXF6eOHTuqR48eTswQAAAAAAAAgBlxhW4i8fHx6tatm/Lnz68tW7Zozpw5Wr58eZLtDhw4oO+++07z58/Xjz/+qFmzZtnX/fDDDwoODtbOnTvVpEkTvf3227p69ao2btyo0aNHa/LkyTp58mQ6ZgUAAAAAAADAFdDQTeTs2bM6evSoBg0aJG9vbxUpUkShoaEJtnFzc9PgwYOVLVs2Pfroo+rcubNWrFhhX1+6dGk9++yzcnNz0xNPPCGbzabu3bvLw8NDISEhkqRTp06la14AAAAAAAAAzI+GbiI7d+5U7ty55e3tbV9WtGjRBNvkzJlTOXPmtN8uVKiQoqKi7Ld9fHzsv1sst05xrly5EtyOj49P89gBAAAAAAAAuDYauolUq1ZNFy5c0I0bN+zLEl9Ne/XqVV2/ft1++8SJEypSpIj9tpubm+MDBQAAAAAAAJDp0NBNJG/evCpdurTGjBmjGzduKCoqSlOmTEmwjc1m05gxY3T9+nUdOnRIc+bMUdu2bZ0UMQAAAAAAAIDMwt3ZAWQ0bm5umjJlioYMGaKaNWuqYMGCCgkJ0d9//23fxsfHRz4+Pqpbt66yZcumtm3bqn379k6MGgAAAAAAAEBmQEP3/xUtWlT79+/XzZs3tWvXLs2dO1dWq1WStG7dOq1cuVKSFBQUpPDwcElSnz59khynZ8+eCW4HBQVp//79CZYlvg0AAAAAAAAAKcGUC4l4eHiod+/e+vrrrxUfH6/z589r7ty5Cg4OdnZoAAAAAAAAADI5GrqJWK1Wffzxx1q2bJmqVaumxo0bq0yZMhowYICzQwMAAAAAAACQyTHlwl0EBgbq66+/dnYYAAAAAAAAAJAAV+gCAAAAAAAAgEnQ0AUAAAAAAAAAk6ChCwAAAAAAAAAmQUMXAAAAAAAAAEyChi4AAAAAAAAAmAQNXQAAAAAAAAAwCRq6AAAAAAAAAGASNHQBAAAAAAAAwCRo6AIAAAAAAACASdDQBQAAAAAAAACToKELAAAAAAAAACZBQxcAAAAAAAAATIKGLgAAAAAAAACYBA1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJNydHQBSxuORx2SJj3F2GAAyGY+8JVO9T3x8vGJiMsbfK5vNJkm6efOmrFark6NJvYeN39PTUxaL8/93Sw0DYCbxFk/Fe2STITdnh5J6uYvp5s2bqdolo9ZKDw+PDBEPNQyAmWToGpZMjcqodehhpEcNo6FrEo80GeYyD2wA5hJvi5NS+IIgJiZGR44cUXx8vGODSiHDMOTu7q5jx47JzS0Dvqi5j4eN32KxqESJEvL09HRAdClHDQNgBoZhKDIyUv9euuTsUB7KpcOHpVTUjIxcK318fFSwYEGnxkUNA2AGZqlhd6tRGbkOPQxH1zAauiZhs9lM+ULCZrNp//798vX1JX4nIH7nM3sONptNf/21V+XLl7/vtoZh6PTp07JarSpWrFiGuDLUMAzduHFDWbNmNeWLg4eJPz4+XqdOndLp06dVvHhxp+Zv1hqWmNmfz4m5Uj6ulItEPs4SGRmpS5cuKX/+/PL29k7276ZhGIqOjpaXl5cpa0tiGbFWGoah69ev68yZM5KkQoUKOS0WV6lhyTHL8/NhkadrIc+kUlrDMqKMWIceRnrVMBq6cLgbN244O4SHQvzOZfb4JfPnEBsbm6Lt4uLidP36dRUuXFje3t4OjiplDMNQfHy8smTJYsoXBw8bf758+XTq1CnFxcXJw8PDARFmPmZ/PifmSvm4Ui4S+aQ3m81mfyP8yCOP3HNbs9eWxDJqPlmzZpUknTlzRvnz53fppo2zZfTnZ1ohT9dCnv9JTQ3LiDJqHXoY6VHDnH/5FADAJdye+8jZH+/Hf27fF7fvGwDA3d3+52VG+Yckbrl9f6T0n8sAkBlRwzImR9cwGroAgDTlKv9VdQXcFwCQOvzdzFi4PwAg5fibmbE4+v6goQsAyBSio6MVGRnp7DAAAEg1ahgAwKyoYY5BQxcAkCm8+OKL2rp1q7PDAAAg1ahhAACzooY5Bg1dAECmcPHiRWeHAADAA6GGAQDMihrmGDR0AQAu77XXXtOpU6c0ZMgQdezYUYMGDUqwvlu3bpo8ebLCw8NVp04dTZ48WUFBQQoKCtKoUaMUExMj6dY3sM6bN08NGjRQYGCgXnzxRe3Zs8cZKQEAMglqGADArFJSw6ZMmaIdO3aobt261LBUoKELAHB5c+fOVeHChTVs2DC98MIL+v777+0vDs6dO6eff/5ZLVq0kCRFRUXpyJEjWrt2rb766itt2LBB06dPlyR9+eWX+vTTTzV58mRt27ZNLVq00Kuvvqpz5845LTcAgGujhgEAzColNax58+aSqGGpRUMXAJCp1K9fXxaLRevWrZMkrVy5UgEBASpWrJikW99GOmTIEGXPnl2PPfaYOnfurBUrVkiSFixYoG7duqlcuXLy8PBQq1atVKpUKft6AAAciRoGADAraljaoqELAMhUPD091ahRI33zzTeSpGXLlqlly5b29bly5VLu3LnttwsVKqQzZ85Ikk6ePKmxY8cqMDDQ/rNv3z6dOnUqfZMAAGRK1DAAgFlRw9KWu7MDgOvLmjWrs0N4KMTvXGaPX3KNHFxNy5Yt9cILL2jXrl2KiIhQgwYN7OuuXLmiGzdu2O+3iIgIFS5cWJJUsGBBvfXWW2rYsKF9++PHj8vHxydd44fzuNrz2ZXycaVcJPLJ6CwW510Xk9Y1LFeuXE7NB87nas/P5JCnayFPc0quhrm5ufE+LJWo3CZhtVqdHcIDsVqt8vPzI34nIX7nM0sOtvh4Z4fgcJ6enrpy5Yokyc/PT6VLl9bw4cP1/PPPJ3ihZLPZNHbsWEVHR+vw4cOaM2eOWrVqJUl64YUXFBYWpkOHDkmSNm/erIYNG+rXX39N/4RMJKM//lPKLM/nlHKlfFwpF4l8Mjo3NzdlzZpVbm5u6TamI2vYjh07HiofwzAeMruMzVUet8lxtedncsjTtZCnudyvhrm5ucnLyytd3oe5Us3iCl2TGLFoq/6JvOzsMAC4oBL5c2nki086OwyHa9WqlSZOnKjdu3dr/PjxatGihUaNGqXBgwcn2TZXrlyqV6+eJKlt27bq3LmzJKljx44yDEM9evTQmTNnVKBAAQ0ePNi+Le6OGgYgo8ud1ao2lQvI/dy/snrcdHY4SYQ821ATPvpI2379Tf0GDVPdp5/TJ1M+Uuc3++hw1CVJ0umLVyVJ8e5eqvtUsCSpYdMWCmncSoejLqnOc810/sp1denaTRfOn9cj+fLp9d59VaJCVfsxUsvL3aoij+RIixQzLGoYgIyOGnYpRXG4Ws2ioWsSx87+q30nLzg7DAAwrc6dO9sbs5JUpEgRlSxZUgEBAUm2DQ0NVWhoaJLlVqs1yXFwf9QwABldwRyeirXlVXSsTRYjztnhJNGoZTs1atlOknQzJk658+ZXkeKPqkTZx3Uz5la8MbE2SVLbV7qo7Std7PvGxMVLik9ynNtu74+7o4YByOioYZkTDV0AQKZy8eJFRUZGKiwsTO3atbv/DgAAZBD/Xr6s82ejtGjB53q2cXNnhwMAQIpRw9IWc+gCADKVPXv2qG3btsqXL5/atm3r7HAAAEixQwf2aUCv7sqd5xE1aNTM2eEAAJBi1LC0xRW6AIBM5cknn9Qff/xx13VBQUHav39/OkcEAEDKBFQL0ler1t11XYXKVbTsp5/TOSIAAFKGGpa2uEIXAAAAAAAAAEyChi4AAAAAAAAAmAQNXQAAAAAAAAAwCRq6AAAAAAAAAGASNHQBAAAAAAAAwCTcnR0AAAAAAGRE7laL3C1u6TZeXLyhOFt8uo0HAHBt1DHXRUMXAOBQtvh4WS3p94GQ1I4XHR2tixcvqmDBgg6MCgBgNu5Wi0oW8JG7Nf1qWJwtXoejLqXqzXBMTLT+vXxZefPld2BkAACzMUMdo4Y9OBq6AACHslosev/LzTpy5rLDxyqRP5dGvvhkqvZ58cUX1b59e7Vo0cJBUd3d0qVLNW3aNK1bty5dxwUApIy7xU3u1vSvYe4WN8XZUr7fwN499FzTFgpp0NBxwd3Fuh9W6av5n2rzxg3pOi4AIGXMUMecVcNc4b0YDV0AgMMdOXNZ+05ecHYYd3Xx4kVnhwAAyMAycg2TpMuXLzk7BABABpaR6xg17MHR0AUAZFqvvfaaTp06pSFDhmju3Ln6559/tH//fvv6AQMGSJLGjBmjqVOn6p9//pGnp6c2bNggb29vNW3aVG+//bYkKSYmRmFhYVqxYoWuXLmiSpUq6f3339ejjz4qSTp06JCGDh2qPXv2qGjRogoKCkr/hAEALmVo/946dyZKn0war+WL/qcTR49o2U8/29dPGTdSkvRWv/e18PM5On70sDw8PbXjl63KmjWr6tZvoA6dX5ckxcbGatGCz7Tppx917doVlX28vDq/EapCRYpKkiKOH9Mnkz7UoQP7lL9gIVWsXCX9EwYAuIz0rmEzp4zXoQP7XOa9WPpNpAEAQAYzd+5cFS5cWMOGDdOgQYPuu/2PP/6o2rVrKzw8XCNGjNCsWbP0+++/S5ImTpyoDRs26LPPPtPmzZtVqVIlvfbaa4qOjlZsbKy6deumMmXK6JdfftFHH32kn376ycHZAQBc3dCxk5Q3fwF1791XXd/sc9/tf9myUZWrVte8pd/p9dB+WvbVAu3fu0eStGDuDO38ZauGfThZc776RmUfL69h/UMVExOtuLg4jRzYV8VLlNDnS1fp7feHKfznzY5ODwDgwtK7hj1WoqRLvRejoQsAQAo99thjatasmaxWq+rWrat8+fLp6NGjMgxDCxcuVJ8+fVSsWDF5eXnpjTfeUGxsrDZs2KBdu3bp9OnT6tevn7y8vFSmTBm9+uqrzk4HAJDJFC5aTMHPPCer1aqqQbWUO88jOhVxQoZh6IeVy/VSp+4qUKiwPD299MJLryouLlY7f9mqfX/t1rkzUXql65vy9PRS8cdKqknrts5OBwCQiTxsDevUo6dLvRdjygUAAFIoX758CW57eHgoPj5eFy5c0PXr19WrVy9ZLP/9rzQ2NlYnT55UTEyMcufOrSxZstjXFS9ePN3iBgBAknxyP5LgttXdXYYRr8uXLunmzRv6cMT7cnP7r47FxcXqTFSkYmNjlTOXj7y8vOzrChYukm5xAwDw8DXMtd6L0dAFAECS1WqVdGsuXE9PT0m3vjAtd+7c9903d+7c8vLy0ty5c1W5cmX78sOHD6tAgQL6+++/deHCBV27dk3ZsmWTJEVGRqZ9EgCATMtivfUmNjY2Vh4eHpKkfy9fVs5cue67b85cueTp6akhYybK16+CffnJE8eUJ28+HTl4QJcvXdKNG9eVNau3JOn82TMOyAIAkBmlSw27fl2SjyTXeC/GlAsAgEzN09NTV65cUfHixeXu7q5Vq1ZJkrZu3apffvklRcewWCxq1aqVJkyYoMjISMXHx2vZsmVq1KiRjh07poCAAJUoUUIjR47UjRs3dOzYMc2dO9eRaQEAMglPT09du3ZNBQsXldVq1eb1ayRJf+z8Vbt/35miY1gsFtV7rpHmz/5E586eUXx8vNb9+J3e6tRBpyMi5OtXUUWKFdPsaZMUffOmTp+M0DeL/ufItAAAmUB61rCwKRNc6r1Yqq7QjYiIUL169bR27VoVLVo02e3Cw8P18ssvJ/imcDObOnWqtm/frvnz5zs7FAAwpRL57/+fVWeN06pVK02cOFG7d+/We++9p+nTp2vEiBGqUaOGWrRooRs3bqToOP3799fUqVP14osv6tKlSypWrJimTJkiPz8/SdLMmTM1ePBg1apVS3nz5lW9evX0448/pjpeAED6ysg1TJLqPdtIC+bO0MH9f6tTj95a9MVnmj1toipWrqqQBg0VfTNldaxjtze18PO5GhjaQ1f+vawChQqr35BRKlmmrCTp/dET9MnEcerYqpF88uRR9VpP6pctGx8oZgBA+snIdSw9a9jMyR+61HsxN8MwjJRuTEM3/Ru6NptNv//+u6ZtjdSfx8+n+/gAXF+5Inm0oHeju667/TeocuXK9ikJknPz5k0dOXJEJUqUSDBXrC0+XlZL+n0g5M7xDMPQ9evX5e3tLTc3t3SLIa08bPzJ3SdS6u7bB0UNA2AWBXN46u36pZS/UFFZ3G991NPdalHJAj5yt6ZfDYuzxetw1CXF2eLTbcyHkcXTXSUL+Djs+M6sY9QwAGZxtxomUccSc3TNSixxDbuzbkl66Br2wHPoRkREaMiQIdq1a5fy58+vtm3b6oMPPkjQxJ05c6YWLFggwzDUuHFj9erVS56enpo6daoOHjyoLFmyaM2aNcqePbveffddHT58WAsWLFBcXJw6duyoHj163DeO8PBw9evXT4GBgdq4caO6du2qF198UWPGjNH27dt15swZ5ciRQ+3bt1f37t0lSSEhIWrTpo1Wr16tY8eO6dFHH9WAAQNUo0YNSdJvv/2mUaNG6dChQypXrpweffTRBGP+9NNPmj59uo4ePap8+fKpXbt2evnll2WxWDRgwAB5e3vr5MmT2r59u/Lmzavhw4frp59+0ooVK+Tp6anevXurdevWD3rqAcBU0rOZ64zxAACu6fabUndL+v1DMC7eyJBvggEA5kMdc20P9K43Pj5e3bp1U/78+bVlyxbNmTNHy5cvT7LdgQMH9N1332n+/Pn68ccfNWvWLPu6H374QcHBwdq5c6eaNGmit99+W1evXtXGjRs1evRoTZ48WSdPnkxRPJGRkSpZsqS2bdumF198UePHj1dERIQWL16sXbt26f3339fEiRN17Ngx+z5LlizR5MmTtXXrVpUrV05Dhw6VdOsLcLp166YGDRro119/1TvvvKOffvrJvt8vv/yi3r17q3Pnztq+fbs++ugjffrpp5o3b16CY3fp0kU7d+6Uv7+/OnXqpMcee0zbtm1Tt27dNHz4cMXExKTyrAMAAABIT3G2eN2MtaXbD2+CAQBpiTrmuh6ooXv27FkdPXpUgwYNkre3t4oUKaLQ0NAE27i5uWnw4MHKli2bHn30UXXu3FkrVqywry9durSeffZZubm56YknnpDNZlP37t3l4eGhkJAQSdKpU6dSHFOrVq3k4eGh7Nmzq2fPnpo0aZKyZ8+uyMhIeXl5SZLOnDmTYPtHH31UWbNmVePGjXX06FFJ0oYNG5Q1a1Z16dJFHh4eqlq1qlq2bGnfb+nSpapXr56ef/55ubu7q3z58uratasWLlxo36ZGjRoKDAyUxWJRjRo15O3trQ4dOsjd3V3BwcGKiYnRuXPnUn7CAQAAAAAAAEAPOOXCzp07lTt3bnl7e9uXJZ5TN2fOnMqZM6f9dqFChRQVFWW/7ePjY//d8v8fj82VK1eC2/HxKe/s58+f3/77+fPnNWrUKO3du1dFixZVhQoVkhwvb9689t/d3d11eyrhqKgoFSpUKMFchcWLF9fff/9tP/bjjz+eYOyiRYsmuJr4ztysVmuC83D7uKnJDQAAAAAAAACkB7xCt1q1arpw4UKCb/5OfDXt1atXdf36dfvtEydOqEiRIvbbaf3lNHcer1evXqpQoYK2bdumZcuWqU+fPik+TsGCBXXy5MkEDdfIyEj770WKFNHx48cT7HPixAnly5fvrrEAAAAAAAAAQFp5oIZu3rx5Vbp0aY0ZM0Y3btxQVFSUpkyZkmAbm82mMWPG6Pr16zp06JDmzJmjtm3bpknQ93PlyhVlyZJFVqtVFy5c0MiRIyVJsbGx9903JCREhmFo6tSpiomJ0Z49e7Ro0SL7+pYtW2rdunVavXq1bDab9u7dq1mzZiWYlgEAAAAAAAAAHOGBGrpubm6aMmWKjh49qpo1a+qVV15RtWrV5OHhYd/Gx8dHPj4+qlu3rjp16qQXXnhB7du3T7PA7+WDDz7Qd999pypVqqhFixYqUKCA/Pz8dODAgfvumzNnTs2ZM0fbtm1T9erVNXDgQDVo0MC+vlKlSpo8ebJmzZqlwMBAvfnmm2rXrp26d+/uyJQAAAAAAAAAIHVz6BYtWlT79+/XzZs3tWvXLs2dO1dWq1WStG7dOq1cuVKSFBQUpPDwcEm663QHPXv2THA7KChI+/fvT7As8e3k3G3fJ598UqtXr052n3Xr1t3zGOXKlUvwJWeJ1atXT/Xq1bvrujFjxiS43aJFC7Vo0cJ++/Y5BAAAAJCxuVstcrek33RqcfEG3xAOAEgz1DHX9UBfiubh4aHevXurd+/eatOmjS5evKi5c+cqODg4reMDAJicEW+Tm8XqsuMBAFyTu9Wi0gVyyWJNv5oSb7PpYNRl3gwDAB4adcy1PVBD12q16uOPP9a4ceM0fvx4eXl5qUGDBnrnnXfSNLjz58+rfv3699xm165daTomACBtuVmsOrd0gGLPHXb4WB55SypvizH33/AOERERqlevntauXauiRYs6KLKkfH19NW/ePAUFBalhw4bq1q2bmjRpkm7jAwDuzd3iJos1/WuYu8VNcbaU7XMm8rS6vdRKM75YrPwFCzk2wDs0r/+ERoyfqsDq1alhAJBBUceS5wrvxR6ooStJgYGB+vrrr9MyliQeeeQRGrYA4AJizx1WbOTfzg4jw1q1apWzQwAAJIMadm/UMADI2Khj92bWOvbADV0AAFzJ8uXLtXz5cl2/fl0hISEaMGCAsmXLplmzZmnlypU6ffq03NzcVKdOHY0aNUpZsmTRP//8o6FDh+rAgQPKnj27qlevrkGDBil79uyKiYlRWFiYVqxYoStXrqhSpUp6//339eijjyYZOyQkRG+++aZatGihDh06qHLlyvrtt9+0d+9e5c+fX7169dLzzz8vSTp37pzGjBmjbdu2yc3NTSEhIerXr5+yZ8+e3qcMAJBBrF+zWut/XK2bN26oWs3aerV7T2X19tayrxZo408/6NzZM3Jzc1PV6jXU4+135eXlpeNHD2vG5PE6duSwvL29Vb5SgLr27KOs3tkUGxurRQs+06afftS1a1dU9vHy6vxGqAoVSfpJlnvVsIIFC6pnz57UMADAPaVHHXujd1+VLOCTZGyz1jFLuo8IAEAGtGPHDn399ddasWKFDhw4oNGjR2v16tWaN2+epk6dqh07dmjhwoXasmWL/UtAhw0bppo1a2r79u1asmSJ9u7dq0WLFkmSJk6cqA0bNuizzz7T5s2bValSJb322muKjo6+byxff/21Bg4cqF9++UX16tXT4MGDFR0drfj4ePXo0UMWi0U//PCDVq5cqTNnzmjw4MEOPTcAgIxt759/aNy0WZo0a56OHzmkuWFTtHXjOn279Gv1HzpaC775QWOmzNBvv4Zr87ofJUkzpkyQf5VAzV+2WuPD5urIwX/043e36tuCuTO085etGvbhZM356huVfby8hvUPVUxMymtYeHi4nnnmGWoYAOC+0qOODXz7rVS9F8vodYyGLgAAkgYMGKA8efIob968euutt7Ry5Uo9+eSTWrx4sR577DFduHBBFy9elI+Pj6KioiRJXl5e2rx5s77//ntZLBZ98803evXVV2UYhhYuXKg+ffqoWLFi8vLy0htvvKHY2Fht2LDhvrE0aNBAfn5+8vT0VOPGjXXlyhWdP39ee/bs0V9//aUhQ4Yoe/bsyp07t/r3769Vq1bp4sWLDj5DAICMqmP3N5Uzl498cudRu46dtWntj6ocGKRxH89W4aLFdPnSRf17+ZJy5sql8+fOSpK8PL302/ZftHXTerm5WfTRjM/UtFVbGYahH1Yu10uduqtAocLy9PTSCy+9qri4WO38Zet9Y7mzhjVv3pwaBgC4r/SoY7FxqX8vlpHrGFMuAAAgJfhCtEKFCikmJkb//vuvpkyZovXr1ytPnjx6/PHHFRsbK8MwJEmTJk3S1KlTNXHiRPXp00dVqlTR0KFDlSdPHl2/fl29evWSxfLf/05jY2N18uTJ+8aSL18+++/u7rdKdXx8vCIiImSz2VS3bt0E23t6eurEiRPKnTv3Q50DAIA5FShY2P573vwFFRsbo2vXrup/n83Sjl9+Vi6f3CpRqsytGhZ/q4a9/f5wfTVvjhbMnaGPTg9RufIV1a1XX+XMlVs3b97QhyPel5vbfzUsLi5WZ6Ii7xsLNQwAkFrpUcdsca71XoyGLgAAkqKiouxzH0VERMjb21szZ87UqVOntG7dOvu6xo0bS7pV1Pfu3auePXvqvffe0+nTp/XBBx9owIABWrRokby8vDR37lxVrlzZPsbhw4dVoECBB46xYMGCypIli8LDw2W1WiVJMTExOnHixF3n5gUAZA4Xzp+Td7ZskqSo0yeVJUtWLf3ffJ07E6UZXyyxr+vVuYOkWzXsyMEDavNyJ73Wo5fOnYnS3E+mauq4URo7bZY8PT01ZMxE+fpVsI9x8sQx5cmbL+ngKUQNAwAkJz3q2LnIk6rqV/qBY8xodYwpFwAAkPThhx/q8uXLioyM1OTJk9WmTRtdvXpVXl5eslqtio6O1ty5c3XgwAHFxsbKYrFo5MiRmjRpkqKjo5UnTx55eXkpd+7cslgsatWqlSZMmKDIyEjFx8dr2bJlatSokY4dO/bAMfr7++vRRx/VmDFjdO3aNd28eVOjR49Wx44dZbPZ0vBsAADMZN6sj3X1yr86d/aMvvxstp5p1FTXr12Th+etGhYTE61vFv1Px48eVlzcrRo2a9pEffnpTMXERCunj488PT2VI5ePLBaL6j3XSPNnf6JzZ88oPj5e6378Tm916qDTEREPHCM1DACQnPSoY91eaedS78W4QhcA4HAeeUtm+HECAgL07LPPymKxqFGjRgoNDdWZM2f07rvvqlatWvL29lbVqlXVtGlTHThwQNKtKRdGjBih2rVrKz4+XtWqVdOIESMkSf3799fUqVP14osv6tKlSypWrJimTJkiPz+/B47R3d1dM2bM0NixY/XMM88oOjpa/v7++vTTT+Xl5fXAxwUAJM8MNcz38Qp649V2srhZ9GTI02r/WlddOHdOU8ePVsdWjZQla1Y9XrGSnqr/rI4dOSxJemfwSM2a+pFee6GpjPh4+flXVo/QfpKkjt3e1MLP52pgaA9d+feyChQqrH5DRqlkmbIPHCM1DACcgzp2q469P/wDl3ov5mbcnggQGZLNZtPvv/+uaVsj9efx884OB4ALKlckjxb0bnTXdbf/BlWuXNn+sZLk3Lx5U0eOHFGJEiWUJUsW+3Ij3iY3y733TUt3jmcYhq5fvy5vb2+5ubmlWwxp5WHjT+4+kVJ33z4oahgAsyiYw1Nv1y+l/IWKyuLuIUlyt1pUukAuWRz0N/Ju4m02HYy6rDhbfLqN+TCyeLqrZAEfhx3fmXWMGgbALO5WwyTqWGKOrlmJJa5hd9YtSQ9dw7hCFwDgUOnZzHXGeAAA1xRni9fBqMtyt6TfPwTj4o0M+SYYAGA+1DHXRkMXAAAAAO4izhavOKZ3BQCYFHXMdfGlaAAAAAAAAABgEjR0AQAAAAAAAMAkaOgCAAAAAAAAgEnQ0AUApCnDMJwdAv4f9wUApEy8pFt/Mvm7mZFQxwDg/qhhGZOjaxgNXQBAmrBarZKkmJgYJ0eC227fF7fvGwDA3f17I05xtnjFx1LDMpLr169Lkjw8PJwcCQBkXNSwjMnRNczdIUdFmns0X07F2PhvC4C0VyJ/rjQ5jru7u7y9vXX27Fl5eHjIYnH+/wwNw1B0dLQsFovc3NycHU6qPUz88fHxOnv2rLy9veXu7txyTw0DYAb7z95QjqwXldvdKndPT0nmqxvpzRpv082bN9P8uIZh6Pr16zpz5ox8fHyc+o9JahgAM6CG3Z+jalZi6VXDaOiaxKDWtbjCCoDD2OLjZX3IBqybm5sKFSqkI0eO6NixY2kU2cMxDEOxsbHy8PAwbUP3YeK3WCwqXry403OnhgEwA8MwFBkZqUuXLiku2tnRmEOcpMMXDYfVGR8fHxUsWNAhx04pahgAM6CG3Z+ja1Zijq5hNHRNwmazmfKFhM1m0/79++Xr60v8TkD8zmeWHB62mXubp6enypQpk2GmXbDZbNq3b59Kly6doc9/ch42fk9PzwxxpbRZa1hiZnk+p5Qr5eNKuUjk4yy3/zGZP39+xcbGJrudzWbTkSNHVKJEiQydT0pl1Hw8PDwyRDyuUsOSY5bn58MiT9dCnkmltIZlRBm1Dj2M9KhhNHThcDdu3HB2CA+F+J3L7PFLrpFDalgsFmXJksXZYUi69eJAkrJkyWLKFwdmj98Vudrz2ZXycaVcJPJxJqvVes+/uTabTdHR0S7zt9nV8kHqmen5+TDI07WQ593dr4ZlRNShB+P8y3YAAAAAAAAAAClCQxcAAAAAAAAATIKGLgAAAAAAAACYBHPoZnCGYUi6NafI7bkUzeR2zGaMXSJ+ZzN7/JL5cyB+53Jk/LePebvOOILZa1hiZn88JeZK+bhSLhL5ZHTkkzE4uo65Wg1Ljlnv/9QiT9dCnq4lM+f5MDXMzXDkOzk8tJiYGO3evdvZYQAAXFTFihXl6enpkGNTwwAAjuaoOkYNAwA42sPUMBq6GVx8fLzi4uJksVjk5ubm7HAAAC7CMAzFx8fL3d1dFotjZmCihgEAHMXRdYwaBgBwlLSoYTR0AQAAAAAAAMAk+FI0AAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJGjoAgAAAAAAAIBJ0NAFAAAAAAAAAJOgoQsAAAAAAAAAJkFDNwM4f/68evToocDAQAUFBWnUqFGKi4u767YbN25U48aNVblyZT333HNav359OkebVGriv+2HH35QvXr10inCe0tN/P/73//UoEEDBQQEqEGDBlqwYEE6R5tUSuOPj4/X1KlTVbduXQUEBKhx48b67rvvnBBxQg/y+Dlw4IAqVaqk8PDwdIry3lKTQ+fOnVWxYkUFBATYfzZt2pTOESeUmvi3b9+u1q1bKyAgQHXr1tWMGTPSOdqkUhp/586dE5z3gIAA+fr6avDgwU6I+j+pOf+ff/65QkJCVKVKFTVu3Fg//PBDOkeblNlrWGJmr2mJmb3G3cns9S4xV6h/dzJ7LUzM7LUxMbPXSkdxtRqWHFerbclxpZp3L65WD5PjanUyOa5WP5PjanU1Oelabw043UsvvWS8/fbbxvXr143jx48bDRs2NGbNmpVkuyNHjhgVK1Y01qxZY8TGxhqrVq0y/P39jcjISCdE/Z+Uxm8YhhETE2PMnDnT8PPzM4KDg9M50rtLafxr1qwxAgMDjV27dhnx8fHGb7/9ZgQGBhrff/+9E6L+T0rjnzdvnhESEmIcO3bMMAzDWLdunVGuXDn7bWdJzePHMAzj+vXrRqNGjYyyZcsav/zySzpGmrzU5BAUFGSEh4enc4T3ltL4Dx48aFSqVMlYunSpER8fb/z9999G9erVjdWrVzsh6v+k9jF026JFi4y6desaUVFR6RBl8lIa/4YNG4yaNWsahw4dMgzDML7//nujXLlyxokTJ9I75ATMXsMSM3tNS8zsNe5OZq93iblC/buT2WthYmavjYmZvVY6iqvVsOS4Wm1LjivVvHtxtXqYHFerk8lxtfqZHFerq8lJz3pLQ9fJjh49apQtWzbBi4FVq1YZTz31VJJtP/roI+PVV19NsKxTp07G5MmTHR5nclITv2HcenB36tTJmDhxYoZ4gZCa+L/44gtjxowZCZa98cYbxogRIxweZ3JSE7/NZjOuXbtmGIZhREdHG4sXLzYCAgKc+gI9tY8fwzCM/v37G5MmTcowhTo1ORw/ftwoV66cceXKlfQM8Z5SE//w4cONPn36JFh2+PBh48yZMw6PMzkP8hgyDMM4dOiQ4e/vb/z666+ODvGeUhP/3LlzjRo1ahgHDx404uPjjTVr1hgVK1Y0Tp8+nZ4hJ2D2GpaY2WtaYmavcXcye71LzBXq353MXgsTM3ttTMzstdJRXK2GJcfValtyXKnm3Yur1cPkuFqdTI6r1c/kuFpdTU5611umXHCyf/75Rz4+PipQoIB9WalSpXTq1Cn9+++/CbY9ePCgypYtm2BZ6dKltW/fvnSJ9W5SE78kffjhh5o9e7aKFy+enmEmKzXxt2/fXl27drXfPn/+vH799VdVqFAh3eJNLDXxWywWeXt7a8uWLapUqZIGDhyoXr16KX/+/Okdtl1qHz/Lly/XsWPH9Oabb6ZnmPeUmhx2796tbNmyKTQ0VDVq1FCjRo20ePHi9A45gdTE/+eff6po0aLq06ePgoKC9Nxzz2n79u3Kly9feodtl9rH0G3Dhg1Ts2bNFBgYmB5hJis18Tds2FB58+bV888/r/Lly6tXr14aM2aMChYsmN5h25m9hiVm9pqWmNlr3J3MXu8Sc4X6dyez18LEzF4bEzN7rXQUV6thyXG12pYcV6p59+Jq9TA5rlYnk+Nq9TM5rlZXk5Pe9ZaGrpNdu3ZNWbNmTbDs9u3r16/fd9ssWbIk2S49pSZ+SU5tPNxNauO/7ezZs+rSpYsqVKigRo0aOTTGe3mQ+KtXr67du3fr008/1aRJk5w6j1Jq4j906JAmTpyoCRMmyGq1pluM95OaHGJiYlS5cmWFhoZq8+bNGjBggEaNGqXVq1enW7yJpSb+y5cva968eWrSpIl+/vlnDR8+XGPHjtX333+fbvEm9iDPgR07duiPP/7IEC/4UhN/bGysypUrp0WLFun333/X8OHDNXDgQO3fvz/d4k3M7DUsMbPXtMTMXuPuZPZ6l5gr1L87mb0WJmb22piY2Wulo7haDUuOq9W25LhSzbsXV6uHyXG1OpkcV6ufyXG1upqc9K63NHSdzNvbWzdu3Eiw7PbtbNmyJVieNWtW3bx5M8GymzdvJtkuPaUm/ozoQeL//fff1apVK5UoUUJhYWFyd3d3eJzJeZD4PT095e7urpo1a6pp06ZauXKlw+NMTkrjj46OVmhoqN577z0VLlw4XWO8n9TcB82aNdPs2bPl5+cnDw8P1a5dW82aNXNqEU5N/J6enqpXr56eeuopubu7q1q1amratKlp4r/tq6++0nPPPZch/submvhHjBihMmXKyN/fX56enmrZsqUqV66sZcuWpVu8iZm9hiVm9pqWmNlr3J3MXu8Sc4X6dyez18LEzF4bEzN7rXQUV6thyXG12pYcV6p59+Jq9TA5rlYnk+Nq9TM5rlZXk5Pe9ZaGrpOVKVNGly5d0rlz5+zLDh06pIIFCypHjhwJti1btqz++eefBMsOHjyoMmXKpEusd5Oa+DOi1Ma/ePFidezYUa+88oomTJggT0/P9Aw3idTEP2bMGI0ZMybBspiYGPn4+KRHqHeV0vh3796to0ePauDAgQoMDLR/FKF79+4aOnRoeoedQGrug8WLFycpRDExMfLy8kqXWO8mNfGXKlVKMTExCZbZbDYZhpEusd5Nap/DcXFxWrt2rZo0aZKeYSYrNfGfOnUqyfl3d3eXh4dHusR6N2avYYmZvaYlZvYadyez17vEXKH+3cnstTAxs9fGxMxeKx3F1WpYclyttiXHlWrevbhaPUyOq9XJ5Lha/UyOq9XV5KR7vU39NL9Ia+3atTNCQ0ONK1eu2L8Fb8qUKUm2O3jwoFGxYkVj1apV9m9XrVixonH48GEnRP2flMZ/pyVLlmSYSfZTGv/3339vlC9f3ti0aZMTokxeSuNfs2aNUalSJWP79u2GzWYz1q5da1SqVMnYuXOnE6L+z4M8fgzDyFCT3ac0h08//dSoWbOm8ddffxk2m81Yv359hviykZTGv3XrVsPPz89Yvny5ER8fb2zfvt2oXLmy8dNPPzkh6v+k5jG0Z88ew8/Pz7h582Y6R5m8lMY/ceJEIygoyNizZ49hs9mM1atXGxUrVjT27t3rhKj/Y/YalpjZa1piZq9xdzJ7vUvMFerfncxeCxMze21MzOy10lFcrYYlx9VqW3Jcqebdi6vVw+S4Wp1MjqvVz+S4Wl1NTnrWWxq6GcDZs2eNnj17GtWrVzdq1KhhjBkzxoiLizMMwzAqV65sfPPNN/ZtN23aZDRp0sSoXLmy0bBhQ2PDhg3OCtsuNfHflpFeIKQ0/kaNGhnlypUzKleunOBn0KBBzgw/Ved/0aJFxjPPPGNUqVLFaNGiRYZ4EfMgjx/DyFiFOqU5xMfHGx9//LERHBxs+Pv7Gw0bNjRWr17tzNANw0jdfbBhwwajRYsWRkBAgFGvXj3jf//7n7PCtktN/KtXrzZq1qzprFDvKqXxx8bGGlOmTDGCg4ONKlWqGM2bNzfdczgj1rDEzF7TEjN7jbuT2etdYq5Q/+5k9lqYmNlrY2Jmr5WO4mo1LDmuVtuS40o1715crR4mx9XqZHJcrX4mx9XqanLSs966GYYJrlsGAAAAAAAAADCHLgAAAAAAAACYBQ1dAAAAAAAAADAJGroAAAAAAAAAYBI0dAEAAAAAAADAJGjoAgAAAAAAAIBJ0NAFAAAAAAAAAJOgoQsAAAAAAAAAJkFDFwAAAAAAAABMgoYuAAAA4ATfffedatasqapVq2r9+vWSpAsXLujpp59WeHi4k6MDAABARkVDF4DpRUREyNfXVxEREZIkX1/fFL8Rvtub6eSsWLFCDRs2lCSFh4fL19f34QIHAGRqixYtUsOGDbVz504FBwdr586datOmjY4fP+7s0AAAAJCB0dAFkKklfjN9L02aNNGqVavSKTIAgCtr1aqVfvnlFy1cuFD169fXsmXL1LdvX4WGhjo7NACAC1m3bp3atm2rmjVrqlKlSnrppZd09OhRSdLKlSvVqFEjBQQE6LnnntN3331n3+/zzz/X008/rYCAALVo0ULbtm2TJA0YMEADBgxIMMadF9SEhIRo8ODBeuKJJ9SsWTPFx8dr8eLFatGihYKCghQQEKBu3brpwoUL9xwrKipKfn5++u233+zbnTt3TuXLl+cfn4Bo6AJwoNtXzo4ZM0bVqlXTsGHDtGrVKjVu3FhVq1ZVixYttGXLFvv2169f1/Dhw1WzZk0FBgaqS5cuOnnypCTp0KFD6tatm5566in5+/vr+eefv+8VtfeT+M20dO8XPEuXLlVISMhDjQkAgCQtXrxYgYGB6tatm3766SfVrl1ba9as0fPPP+/s0AAALiIyMlK9evVS165dtW3bNm3YsEGGYejjjz9WeHi43nvvPb3zzjvauXOn3n33XfXr108HDx7U0qVLNX36dI0bN047d+5Uu3bt9Prrr+vSpUspGvfPP//U6tWrNW/ePO3Zs0cjR47U0KFDFR4ertWrV+vo0aOaN2+eJCU7lpeXl5544gl988039uOuWLFCAQEBKl68uCNOF2AqNHQBONy1a9f0888/q0qVKhoyZIgGDx6s7du3q2fPnurZs6f++ecfSdLw4cO1e/duLV26VFu3blXevHnVp08fSVLPnj1VtmxZrVmzRjt27FDt2rU1dOjQh4or8Zvpe73gAQDAkfLlyyd3d3dnhwEAcCF58uTRqlWrFBISoqtXryoyMlK5c+dWVFSUli9frmeeeUZ169aVxWJRnTp19OWXX6pAgQJatmyZ2rRpo4CAAFksFrVu3Vpz585VlixZUjRugwYNlDNnTuXMmVNly5bVt99+K39/f12+fFlnzpxRnjx5FBUVJUn3HKtly5b6/vvvFRMTY9+2ZcuWDjtfgJnwqhGAwzVr1kyenp5asWKF2rVrp2rVqkmSgoODFRISooULF6p///5atWqVwsLCVKhQIUnSu+++q2PHjkmSZsyYoQIFCsgwDJ08eVI5c+a0vwhIK7df8BQvXjzJCx4AAAAAMBMPDw99++23Wrhwodzc3FS2bFldvXpV7u7uOnPmjPz8/BJs7+/vL0k6e/asChcunGBdlSpVUjxu/vz57b9bLBbNmzdPK1eulPf/tXc3IVFucRzHvxpNJRWTBfkCBY1DERhBUG5rU0MpKWSQlBEFYlC0sMJNiwqyIA0LAiECG6RFYIQESYFNgYRtcmNTuxhDpEVvZpnOXcQMTZY37jXvHfl+YODhnBnO4WzO4TeH/5OXx+rVq/nw4QPJZPJvx9qyZQunTp2ip6eHoqIiEokEW7du/f0FkGYxA11Jf1xqQ08kEjx58oSOjo503/j4OGVlZbx9+5YvX75kbOaLFy+mtLQUgIGBAerr6xkeHiYUCpGfn58+BEyXqQ48kiRJkpRN7t69y40bN+jo6GDlypUAnD59mng8TmFhIYODgxnfv3btGuvXr6ewsJDXr19n9DU3N1NRUUFubi6fP39Ot39fCzclJycn/Xz9+nUeP37MnTt3WLZsGQB1dXXp/qnGCoVClJeX09XVRVFREZFIhLy8vH+4GtLsYskFSX9cakMvKCjg8OHD9PX1pT9dXV2cPXuWpUuXEggEMjbzN2/ecO7cOYaGhjh69CjHjh2jt7eXaDTKjh07pn2eqQNPe3s7PT09tLW1TfrXWpIkSZKywfv378nNzWX+/Pkkk0kePnxIZ2cnY2NjVFZW0t3dzaNHj5iYmCAWi9Ha2sqiRYuoqqri5s2bPHv2jImJCW7dukU0GmXJkiWEQiH6+voYGhpidHSUK1euZAS4P0pdkJk7dy5fv37l9u3bxGIxxsbGAKYcC7699yQWi9Hd3U1VVdWMrJuUDbx2JmnGVFdXc+bMGcrKyli3bh39/f0cOnSI+vp69u3bx86dO2ltbaWkpIRgMEhLSwsvXrzg48ePjI+Ps2DBAgBevnyZrmubqqc0HX488MRiMTo7OwmHw9M2hiRJkiTNhMrKSp4+fcr27duZM2cOq1atora2lmg0SmlpKU1NTTQ1NZFIJCguLubixYuEw2HC4TDv3r2joaGB4eFhSkpKaGtrIz8/n927d9Pf309FRQWBQIDa2tpJJRO+d+DAAeLxOJs3b2bevHmsXbuWPXv20NvbC0B5efkvxwJYs2YNK1asYGRkhA0bNszIuknZwEBX0ozZtm0bIyMjNDY2Mjg4SDAYZP/+/ezduxeAkydP0tzczK5duxgdHWXjxo1cunSJ5cuXc/z4cRoaGvj06RMFBQVUV1dz4cIF4vE4wWBwWuY31YFnOoNjSZIA2tvbf9r+/PnzGZ6JJGk2CgQCnD9/flL7kSNHAIhEIkQikZ/+tqamhpqamkntCxcupKWlJaPt4MGD6ecHDx5k9AWDQa5evTrlPH81VkpxcXG6vq+kb3KS012EUpIkSZIkSfoXXr16xcDAACdOnODevXvpGrySvKErSZIkSZKk/5nLly9z//59GhsbDXOlH3hDV9KstWnTpilLJaTelipJkiRJkpQtDHQlSZIkSZIkKUvk/tcTkCRJkiRJkiT9HgNdSZIkSZIkScoSBrqSJEmSJEmSlCUMdCVJkiRJkiQpSxjoSpIkSZIkSVKWMNCVJEmSJEmSpCxhoCtJkiRJkiRJWcJAV5IkSZIkSZKyxF8kKnK/JvlRcQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1400x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visual comparison of tuned vs baseline models\n",
    "if comparison_df.empty:\n",
    "    print(\"Aucune donnée de comparaison disponible : exécutez les cellules précédentes.\")\n",
    "else:\n",
    "    plot_df = comparison_df.copy()\n",
    "    plot_df = plot_df.sort_values(\"recall_fail\", ascending=False)\n",
    "    metrics = [\"recall_fail\", \"f1\", \"accuracy\"]\n",
    "    fig, axes = plt.subplots(1, len(metrics), figsize=(14, 5), sharey=True)\n",
    "    for ax, metric in zip(axes, metrics):\n",
    "        sns.barplot(data=plot_df, x=metric, y=\"model\", hue=\"type\", ax=ax)\n",
    "        ax.set_title(metric.replace(\"_\", \" \").title())\n",
    "        ax.set_xlabel(metric)\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.legend(title=\"type\", loc=\"lower right\")\n",
    "    fig.suptitle(\"Baselines vs modèles tunés (CV)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f5fa9",
   "metadata": {},
   "source": [
    "## 7. Évaluation sur test + sauvegarde du meilleur modèle\n",
    "- Sélection du meilleur tuned (rappel_fail CV).\n",
    "- Refit sur tout le train exam, évaluation sur test, sauvegarde `models/exam_tuned.joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b09d750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best tuned model: xgb_grid\n",
      "Model saved to ..\\models\\exam_tuned.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\anaconda3\\envs\\Data\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:44:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "search_map = {\n",
    "    \"xgb_grid\": grid_xgb,\n",
    "    \"lgbm_random\": rand_lgbm,\n",
    "    \"optuna_xgb\": SimpleNamespace(best_estimator_=optuna_best_estimator),\n",
    "}\n",
    "\n",
    "best_row = (\n",
    "    comparison_df[comparison_df[\"type\"] == \"tuned\"]\n",
    "    .sort_values(\"recall_fail\", ascending=False)\n",
    "    .iloc[0]\n",
    ")\n",
    "best_name = best_row[\"model\"]\n",
    "best_search = search_map[best_name]\n",
    "\n",
    "best_estimator = best_search.best_estimator_\n",
    "best_estimator.fit(X_exam, y_exam)\n",
    "\n",
    "X_test_exam, y_test_exam = exam_split[\"X_test\"], exam_split[\"y_test\"]\n",
    "test_pred = best_estimator.predict(X_test_exam)\n",
    "if hasattr(best_estimator, \"predict_proba\"):\n",
    "    test_proba = best_estimator.predict_proba(X_test_exam)[:, 1]\n",
    "    test_auc = roc_auc_score(y_test_exam, test_proba)\n",
    "else:\n",
    "    test_proba = None\n",
    "    test_auc = np.nan\n",
    "\n",
    "test_metrics = {\n",
    "    \"recall_fail\": recall_score(y_test_exam, test_pred, pos_label=0),\n",
    "    \"f1\": f1_score(y_test_exam, test_pred),\n",
    "    \"accuracy\": accuracy_score(y_test_exam, test_pred),\n",
    "    \"roc_auc\": test_auc,\n",
    "}\n",
    "\n",
    "report = classification_report(y_test_exam, test_pred, target_names=[\"fail\", \"pass\"], output_dict=True)\n",
    "\n",
    "models_dir = Path(\"..\") / \"models\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_path = models_dir / \"exam_tuned.joblib\"\n",
    "joblib.dump(best_estimator, model_path)\n",
    "\n",
    "print(f\"Best tuned model: {best_name}\")\n",
    "pd.DataFrame([test_metrics])\n",
    "pd.DataFrame(report).T\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
